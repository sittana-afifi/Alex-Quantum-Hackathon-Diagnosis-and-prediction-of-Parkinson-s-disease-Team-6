{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kjdM8AoKe4o7"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'error'\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Getting requirements to build wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [15 lines of output]\n",
            "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "      rather than 'sklearn' for pip commands.\n",
            "      \n",
            "      Here is how to fix this error in the main use cases:\n",
            "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "      - if the 'sklearn' package is used by one of your dependencies,\n",
            "        it would be great if you take some time to track which package uses\n",
            "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "      - as a last resort, set the environment variable\n",
            "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "      \n",
            "      More information is available at\n",
            "      https://github.com/scikit-learn/sklearn-pypi-package\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× Getting requirements to build wheel did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "PeBIv0LHMtuc",
        "outputId": "5c0a403a-d301-4462-85cb-116993bb5e0e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-aa0568c6-bc62-4ed9-abba-7d1543d296df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0_level_0</th>\n",
              "      <th>Unnamed: 1_level_0</th>\n",
              "      <th>Baseline Features</th>\n",
              "      <th>Unnamed: 3_level_0</th>\n",
              "      <th>Unnamed: 4_level_0</th>\n",
              "      <th>Unnamed: 5_level_0</th>\n",
              "      <th>Unnamed: 6_level_0</th>\n",
              "      <th>Unnamed: 7_level_0</th>\n",
              "      <th>Unnamed: 8_level_0</th>\n",
              "      <th>Unnamed: 9_level_0</th>\n",
              "      <th>...</th>\n",
              "      <th>Unnamed: 745_level_0</th>\n",
              "      <th>Unnamed: 746_level_0</th>\n",
              "      <th>Unnamed: 747_level_0</th>\n",
              "      <th>Unnamed: 748_level_0</th>\n",
              "      <th>Unnamed: 749_level_0</th>\n",
              "      <th>Unnamed: 750_level_0</th>\n",
              "      <th>Unnamed: 751_level_0</th>\n",
              "      <th>Unnamed: 752_level_0</th>\n",
              "      <th>Unnamed: 753_level_0</th>\n",
              "      <th>Unnamed: 754_level_0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>PPE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>numPulses</th>\n",
              "      <th>numPeriodsPulses</th>\n",
              "      <th>meanPeriodPulses</th>\n",
              "      <th>stdDevPeriodPulses</th>\n",
              "      <th>locPctJitter</th>\n",
              "      <th>...</th>\n",
              "      <th>tqwt_kurtosisValue_dec_28</th>\n",
              "      <th>tqwt_kurtosisValue_dec_29</th>\n",
              "      <th>tqwt_kurtosisValue_dec_30</th>\n",
              "      <th>tqwt_kurtosisValue_dec_31</th>\n",
              "      <th>tqwt_kurtosisValue_dec_32</th>\n",
              "      <th>tqwt_kurtosisValue_dec_33</th>\n",
              "      <th>tqwt_kurtosisValue_dec_34</th>\n",
              "      <th>tqwt_kurtosisValue_dec_35</th>\n",
              "      <th>tqwt_kurtosisValue_dec_36</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.85247</td>\n",
              "      <td>0.71826</td>\n",
              "      <td>0.57227</td>\n",
              "      <td>240</td>\n",
              "      <td>239</td>\n",
              "      <td>0.008064</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.00218</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5620</td>\n",
              "      <td>2.6445</td>\n",
              "      <td>3.8686</td>\n",
              "      <td>4.2105</td>\n",
              "      <td>5.1221</td>\n",
              "      <td>4.4625</td>\n",
              "      <td>2.6202</td>\n",
              "      <td>3.0004</td>\n",
              "      <td>18.9405</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76686</td>\n",
              "      <td>0.69481</td>\n",
              "      <td>0.53966</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>0.008258</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.00195</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5589</td>\n",
              "      <td>3.6107</td>\n",
              "      <td>23.5155</td>\n",
              "      <td>14.1962</td>\n",
              "      <td>11.0261</td>\n",
              "      <td>9.5082</td>\n",
              "      <td>6.5245</td>\n",
              "      <td>6.3431</td>\n",
              "      <td>45.1780</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.85083</td>\n",
              "      <td>0.67604</td>\n",
              "      <td>0.58982</td>\n",
              "      <td>232</td>\n",
              "      <td>231</td>\n",
              "      <td>0.008340</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.00176</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5643</td>\n",
              "      <td>2.3308</td>\n",
              "      <td>9.4959</td>\n",
              "      <td>10.7458</td>\n",
              "      <td>11.0177</td>\n",
              "      <td>4.8066</td>\n",
              "      <td>2.9199</td>\n",
              "      <td>3.1495</td>\n",
              "      <td>4.7666</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.41121</td>\n",
              "      <td>0.79672</td>\n",
              "      <td>0.59257</td>\n",
              "      <td>178</td>\n",
              "      <td>177</td>\n",
              "      <td>0.010858</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.00419</td>\n",
              "      <td>...</td>\n",
              "      <td>3.7805</td>\n",
              "      <td>3.5664</td>\n",
              "      <td>5.2558</td>\n",
              "      <td>14.0403</td>\n",
              "      <td>4.2235</td>\n",
              "      <td>4.6857</td>\n",
              "      <td>4.8460</td>\n",
              "      <td>6.2650</td>\n",
              "      <td>4.0603</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.32790</td>\n",
              "      <td>0.79782</td>\n",
              "      <td>0.53028</td>\n",
              "      <td>236</td>\n",
              "      <td>235</td>\n",
              "      <td>0.008162</td>\n",
              "      <td>0.002669</td>\n",
              "      <td>0.00535</td>\n",
              "      <td>...</td>\n",
              "      <td>6.1727</td>\n",
              "      <td>5.8416</td>\n",
              "      <td>6.0805</td>\n",
              "      <td>5.7621</td>\n",
              "      <td>7.7817</td>\n",
              "      <td>11.6891</td>\n",
              "      <td>8.2103</td>\n",
              "      <td>5.0559</td>\n",
              "      <td>6.1164</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.80903</td>\n",
              "      <td>0.56355</td>\n",
              "      <td>0.28385</td>\n",
              "      <td>417</td>\n",
              "      <td>416</td>\n",
              "      <td>0.004627</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.00064</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0706</td>\n",
              "      <td>3.0190</td>\n",
              "      <td>3.1212</td>\n",
              "      <td>2.4921</td>\n",
              "      <td>3.5844</td>\n",
              "      <td>3.5400</td>\n",
              "      <td>3.3805</td>\n",
              "      <td>3.2003</td>\n",
              "      <td>6.8671</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.16084</td>\n",
              "      <td>0.56499</td>\n",
              "      <td>0.59194</td>\n",
              "      <td>415</td>\n",
              "      <td>413</td>\n",
              "      <td>0.004550</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.00143</td>\n",
              "      <td>...</td>\n",
              "      <td>1.9704</td>\n",
              "      <td>1.7451</td>\n",
              "      <td>1.8277</td>\n",
              "      <td>2.4976</td>\n",
              "      <td>5.2981</td>\n",
              "      <td>4.2616</td>\n",
              "      <td>6.3042</td>\n",
              "      <td>10.9058</td>\n",
              "      <td>28.4170</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>251</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88389</td>\n",
              "      <td>0.72335</td>\n",
              "      <td>0.46815</td>\n",
              "      <td>381</td>\n",
              "      <td>380</td>\n",
              "      <td>0.005069</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.00076</td>\n",
              "      <td>...</td>\n",
              "      <td>51.5607</td>\n",
              "      <td>44.4641</td>\n",
              "      <td>26.1586</td>\n",
              "      <td>6.3076</td>\n",
              "      <td>2.8601</td>\n",
              "      <td>2.5361</td>\n",
              "      <td>3.5377</td>\n",
              "      <td>3.3545</td>\n",
              "      <td>5.0424</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>251</td>\n",
              "      <td>0</td>\n",
              "      <td>0.83782</td>\n",
              "      <td>0.74890</td>\n",
              "      <td>0.49823</td>\n",
              "      <td>340</td>\n",
              "      <td>339</td>\n",
              "      <td>0.005679</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.00092</td>\n",
              "      <td>...</td>\n",
              "      <td>19.1607</td>\n",
              "      <td>12.8312</td>\n",
              "      <td>8.9434</td>\n",
              "      <td>2.2044</td>\n",
              "      <td>1.9496</td>\n",
              "      <td>1.9664</td>\n",
              "      <td>2.6801</td>\n",
              "      <td>2.8332</td>\n",
              "      <td>3.7131</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>251</td>\n",
              "      <td>0</td>\n",
              "      <td>0.81304</td>\n",
              "      <td>0.76471</td>\n",
              "      <td>0.46374</td>\n",
              "      <td>340</td>\n",
              "      <td>339</td>\n",
              "      <td>0.005676</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.00078</td>\n",
              "      <td>...</td>\n",
              "      <td>62.9927</td>\n",
              "      <td>21.8152</td>\n",
              "      <td>9.2457</td>\n",
              "      <td>4.8555</td>\n",
              "      <td>3.0551</td>\n",
              "      <td>3.0415</td>\n",
              "      <td>4.0116</td>\n",
              "      <td>2.6217</td>\n",
              "      <td>3.1527</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>756 rows × 755 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa0568c6-bc62-4ed9-abba-7d1543d296df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa0568c6-bc62-4ed9-abba-7d1543d296df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa0568c6-bc62-4ed9-abba-7d1543d296df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6ffafd64-f0e6-4f74-8a70-012cf1bcf995\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ffafd64-f0e6-4f74-8a70-012cf1bcf995')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6ffafd64-f0e6-4f74-8a70-012cf1bcf995 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_97521cd7-ed34-41c0-8fd1-852441b9e126\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_97521cd7-ed34-41c0-8fd1-852441b9e126 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Unnamed: 0_level_0 Unnamed: 1_level_0 Baseline Features  \\\n",
              "                    id             gender               PPE   \n",
              "0                    0                  1           0.85247   \n",
              "1                    0                  1           0.76686   \n",
              "2                    0                  1           0.85083   \n",
              "3                    1                  0           0.41121   \n",
              "4                    1                  0           0.32790   \n",
              "..                 ...                ...               ...   \n",
              "751                250                  0           0.80903   \n",
              "752                250                  0           0.16084   \n",
              "753                251                  0           0.88389   \n",
              "754                251                  0           0.83782   \n",
              "755                251                  0           0.81304   \n",
              "\n",
              "    Unnamed: 3_level_0 Unnamed: 4_level_0 Unnamed: 5_level_0  \\\n",
              "                   DFA               RPDE          numPulses   \n",
              "0              0.71826            0.57227                240   \n",
              "1              0.69481            0.53966                234   \n",
              "2              0.67604            0.58982                232   \n",
              "3              0.79672            0.59257                178   \n",
              "4              0.79782            0.53028                236   \n",
              "..                 ...                ...                ...   \n",
              "751            0.56355            0.28385                417   \n",
              "752            0.56499            0.59194                415   \n",
              "753            0.72335            0.46815                381   \n",
              "754            0.74890            0.49823                340   \n",
              "755            0.76471            0.46374                340   \n",
              "\n",
              "    Unnamed: 6_level_0 Unnamed: 7_level_0 Unnamed: 8_level_0  \\\n",
              "      numPeriodsPulses   meanPeriodPulses stdDevPeriodPulses   \n",
              "0                  239           0.008064           0.000087   \n",
              "1                  233           0.008258           0.000073   \n",
              "2                  231           0.008340           0.000060   \n",
              "3                  177           0.010858           0.000183   \n",
              "4                  235           0.008162           0.002669   \n",
              "..                 ...                ...                ...   \n",
              "751                416           0.004627           0.000052   \n",
              "752                413           0.004550           0.000220   \n",
              "753                380           0.005069           0.000103   \n",
              "754                339           0.005679           0.000055   \n",
              "755                339           0.005676           0.000037   \n",
              "\n",
              "    Unnamed: 9_level_0  ...      Unnamed: 745_level_0  \\\n",
              "          locPctJitter  ... tqwt_kurtosisValue_dec_28   \n",
              "0              0.00218  ...                    1.5620   \n",
              "1              0.00195  ...                    1.5589   \n",
              "2              0.00176  ...                    1.5643   \n",
              "3              0.00419  ...                    3.7805   \n",
              "4              0.00535  ...                    6.1727   \n",
              "..                 ...  ...                       ...   \n",
              "751            0.00064  ...                    3.0706   \n",
              "752            0.00143  ...                    1.9704   \n",
              "753            0.00076  ...                   51.5607   \n",
              "754            0.00092  ...                   19.1607   \n",
              "755            0.00078  ...                   62.9927   \n",
              "\n",
              "         Unnamed: 746_level_0      Unnamed: 747_level_0  \\\n",
              "    tqwt_kurtosisValue_dec_29 tqwt_kurtosisValue_dec_30   \n",
              "0                      2.6445                    3.8686   \n",
              "1                      3.6107                   23.5155   \n",
              "2                      2.3308                    9.4959   \n",
              "3                      3.5664                    5.2558   \n",
              "4                      5.8416                    6.0805   \n",
              "..                        ...                       ...   \n",
              "751                    3.0190                    3.1212   \n",
              "752                    1.7451                    1.8277   \n",
              "753                   44.4641                   26.1586   \n",
              "754                   12.8312                    8.9434   \n",
              "755                   21.8152                    9.2457   \n",
              "\n",
              "         Unnamed: 748_level_0      Unnamed: 749_level_0  \\\n",
              "    tqwt_kurtosisValue_dec_31 tqwt_kurtosisValue_dec_32   \n",
              "0                      4.2105                    5.1221   \n",
              "1                     14.1962                   11.0261   \n",
              "2                     10.7458                   11.0177   \n",
              "3                     14.0403                    4.2235   \n",
              "4                      5.7621                    7.7817   \n",
              "..                        ...                       ...   \n",
              "751                    2.4921                    3.5844   \n",
              "752                    2.4976                    5.2981   \n",
              "753                    6.3076                    2.8601   \n",
              "754                    2.2044                    1.9496   \n",
              "755                    4.8555                    3.0551   \n",
              "\n",
              "         Unnamed: 750_level_0      Unnamed: 751_level_0  \\\n",
              "    tqwt_kurtosisValue_dec_33 tqwt_kurtosisValue_dec_34   \n",
              "0                      4.4625                    2.6202   \n",
              "1                      9.5082                    6.5245   \n",
              "2                      4.8066                    2.9199   \n",
              "3                      4.6857                    4.8460   \n",
              "4                     11.6891                    8.2103   \n",
              "..                        ...                       ...   \n",
              "751                    3.5400                    3.3805   \n",
              "752                    4.2616                    6.3042   \n",
              "753                    2.5361                    3.5377   \n",
              "754                    1.9664                    2.6801   \n",
              "755                    3.0415                    4.0116   \n",
              "\n",
              "         Unnamed: 752_level_0      Unnamed: 753_level_0 Unnamed: 754_level_0  \n",
              "    tqwt_kurtosisValue_dec_35 tqwt_kurtosisValue_dec_36                class  \n",
              "0                      3.0004                   18.9405                    1  \n",
              "1                      6.3431                   45.1780                    1  \n",
              "2                      3.1495                    4.7666                    1  \n",
              "3                      6.2650                    4.0603                    1  \n",
              "4                      5.0559                    6.1164                    1  \n",
              "..                        ...                       ...                  ...  \n",
              "751                    3.2003                    6.8671                    0  \n",
              "752                   10.9058                   28.4170                    0  \n",
              "753                    3.3545                    5.0424                    0  \n",
              "754                    2.8332                    3.7131                    0  \n",
              "755                    2.6217                    3.1527                    0  \n",
              "\n",
              "[756 rows x 755 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"Data/pd_speech_features.csv\", header=[1])\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjKmsi2ec0IT"
      },
      "source": [
        "ALL FEATURES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtHvPaFUcpYg",
        "outputId": "b9a5be25-0134-4ec0-9d4f-dfefe2158e85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-855518625.py:21: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [22:03:29] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Accuracies:\n",
            "Logistic Regression: 0.8618\n",
            "Random Forest: 0.8684\n",
            "SVM: 0.8553\n",
            "XGBoost: 0.8947\n",
            "Neural Network: 0.8684\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ML models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# =====================\n",
        "# 1. Load dataset\n",
        "# =====================\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
        "y = df[\"Unnamed: 754_level_0\"].values\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Standardize features (important for SVM, Logistic, NN)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# =====================\n",
        "# 2. Logistic Regression\n",
        "# =====================\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred = log_reg.predict(X_test)\n",
        "acc_log = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# =====================\n",
        "# 3. Random Forest\n",
        "# =====================\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# =====================\n",
        "# 4. Support Vector Machine\n",
        "# =====================\n",
        "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "acc_svm = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# =====================\n",
        "# 5. XGBoost\n",
        "# =====================\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred = xgb.predict(X_test)\n",
        "acc_xgb = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# =====================\n",
        "# 6. Neural Network (Deep Learning)\n",
        "# =====================\n",
        "# One-hot encode target\n",
        "y_train_nn = to_categorical(y_train)\n",
        "y_test_nn = to_categorical(y_test)\n",
        "\n",
        "nn = Sequential()\n",
        "nn.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "nn.add(Dropout(0.3))\n",
        "nn.add(Dense(32, activation='relu'))\n",
        "nn.add(Dense(y_train_nn.shape[1], activation='softmax'))\n",
        "\n",
        "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "nn.fit(X_train, y_train_nn, validation_split=0.2, epochs=50, batch_size=16, verbose=0)\n",
        "\n",
        "loss, acc_nn = nn.evaluate(X_test, y_test_nn, verbose=0)\n",
        "\n",
        "# =====================\n",
        "# 7. Results\n",
        "# =====================\n",
        "results = {\n",
        "    \"Logistic Regression\": acc_log,\n",
        "    \"Random Forest\": acc_rf,\n",
        "    \"SVM\": acc_svm,\n",
        "    \"XGBoost\": acc_xgb,\n",
        "    \"Neural Network\": acc_nn\n",
        "}\n",
        "\n",
        "print(\"\\nModel Accuracies:\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlw5ExPY78d6",
        "outputId": "3fb97a82-d9a0-4fca-c78c-a18282da0fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Baseline  Intensity  Formants  Bandwidth  VocalFold      MFCC    Wavelet  \\\n",
            "0 -0.085724  -0.071582 -1.426155   0.236350  -1.244790 -0.393715 -10.767724   \n",
            "1  0.227617  -0.611652 -1.421387   0.302269  -1.002787 -0.047907 -11.267948   \n",
            "2 -1.332900  -1.146479 -1.458608   0.081536  -2.396363  3.380602 -13.057346   \n",
            "3 -1.933424   0.971632  1.239160   0.117355  -2.039840 -1.687959  -8.277880   \n",
            "4 -2.210948   0.991717  1.467792  -0.500374  -2.201670 -3.312962  -5.882762   \n",
            "\n",
            "   Unnamed: 754_level_0  \n",
            "0                     1  \n",
            "1                     1  \n",
            "2                     1  \n",
            "3                     1  \n",
            "4                     1  \n",
            "Final shape: (756, 8)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "df = pd.read_csv(\"parkinsons_data/pd_speech_features.csv\", header=[0,1])\n",
        "\n",
        "\n",
        "feature_groups = {\n",
        "    \"Baseline\": list(range(2, 22)),       # example: cols 2–21\n",
        "    \"Intensity\": list(range(23, 25)),     # cols 22–24\n",
        "    \"Formants\": list(range(26, 29)),      # cols 25–28\n",
        "    \"Bandwidth\": list(range(30, 33)),     # cols 29–31\n",
        "    \"VocalFold\": list(range(34, 55)),     # cols 32–35\n",
        "    \"MFCC\": list(range(56, 139)),          # cols 36–48\n",
        "    \"Wavelet\": list(range(140, df.shape[1]-1))  # all until the last column before class\n",
        "}\n",
        "\n",
        "\n",
        "# New dataframe to hold compressed features\n",
        "df_grouped = pd.DataFrame(index=df.index)\n",
        "\n",
        "# Function: compress group with PCA (1 component)\n",
        "def group_with_pca(df, cols, new_name):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(df.iloc[:, cols])\n",
        "    pca = PCA(n_components=1)\n",
        "    df_grouped[new_name] = pca.fit_transform(X_scaled).ravel()  # ensure it's 1D\n",
        "\n",
        "# Apply PCA for each group\n",
        "for feature, cols in feature_groups.items():\n",
        "    group_with_pca(df, cols, feature)\n",
        "\n",
        "# Add class column back\n",
        "df_grouped[\"Unnamed: 754_level_0\"] = df[\"Unnamed: 754_level_0\"].values\n",
        "\n",
        "# Show result\n",
        "print(df_grouped.head())\n",
        "print(\"Final shape:\", df_grouped.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAYk51lPeedB",
        "outputId": "5c7927ec-c93b-4952-b991-cd0e9f2db0f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 283ms/step - accuracy: 0.6754 - loss: 1.3116 - val_accuracy: 0.7566 - val_loss: 1.1483 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7090 - loss: 1.1346 - val_accuracy: 0.7566 - val_loss: 1.0969 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7624 - loss: 1.0613 - val_accuracy: 0.7434 - val_loss: 1.0638 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7542 - loss: 1.0843 - val_accuracy: 0.7434 - val_loss: 1.0468 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7520 - loss: 1.0709 - val_accuracy: 0.7434 - val_loss: 1.0411 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7860 - loss: 1.0116 - val_accuracy: 0.7434 - val_loss: 1.0312 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7859 - loss: 0.9871 - val_accuracy: 0.7434 - val_loss: 1.0294 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7921 - loss: 0.9645 - val_accuracy: 0.7434 - val_loss: 1.0269 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7744 - loss: 0.9963 - val_accuracy: 0.7434 - val_loss: 1.0225 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7916 - loss: 1.0099 - val_accuracy: 0.7434 - val_loss: 1.0212 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7993 - loss: 0.9744 - val_accuracy: 0.7434 - val_loss: 1.0132 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7902 - loss: 0.9855 - val_accuracy: 0.7500 - val_loss: 1.0091 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8244 - loss: 0.9228 - val_accuracy: 0.7500 - val_loss: 1.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8175 - loss: 0.9397 - val_accuracy: 0.7434 - val_loss: 0.9947 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7790 - loss: 0.9672 - val_accuracy: 0.7500 - val_loss: 0.9808 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8350 - loss: 0.9021 - val_accuracy: 0.7697 - val_loss: 0.9732 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8015 - loss: 0.9597 - val_accuracy: 0.7632 - val_loss: 0.9626 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 0.8978 - val_accuracy: 0.7632 - val_loss: 0.9558 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8008 - loss: 0.9328 - val_accuracy: 0.7632 - val_loss: 0.9488 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8573 - loss: 0.8728 - val_accuracy: 0.7697 - val_loss: 0.9398 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8374 - loss: 0.8767 - val_accuracy: 0.7763 - val_loss: 0.9336 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.8711 - val_accuracy: 0.7895 - val_loss: 0.9320 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8110 - loss: 0.8934 - val_accuracy: 0.7961 - val_loss: 0.9263 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7993 - loss: 0.9038 - val_accuracy: 0.7961 - val_loss: 0.9206 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8338 - loss: 0.8697 - val_accuracy: 0.7961 - val_loss: 0.9147 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7917 - loss: 0.9051 - val_accuracy: 0.7829 - val_loss: 0.9129 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8049 - loss: 0.9364 - val_accuracy: 0.7829 - val_loss: 0.9147 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8341 - loss: 0.8737 - val_accuracy: 0.7829 - val_loss: 0.9101 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8051 - loss: 0.8941 - val_accuracy: 0.7895 - val_loss: 0.9009 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7922 - loss: 0.9138 - val_accuracy: 0.7829 - val_loss: 0.8941 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7996 - loss: 0.8867 - val_accuracy: 0.7895 - val_loss: 0.8909 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8065 - loss: 0.9119 - val_accuracy: 0.7961 - val_loss: 0.8844 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - loss: 0.8744 - val_accuracy: 0.8092 - val_loss: 0.8802 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8453 - loss: 0.8464 - val_accuracy: 0.7961 - val_loss: 0.8760 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8171 - loss: 0.8721 - val_accuracy: 0.7895 - val_loss: 0.8715 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8511 - loss: 0.8400 - val_accuracy: 0.7895 - val_loss: 0.8716 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8178 - loss: 0.8809 - val_accuracy: 0.7961 - val_loss: 0.8716 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8216 - loss: 0.8447 - val_accuracy: 0.7763 - val_loss: 0.8709 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8280 - loss: 0.8339 - val_accuracy: 0.7829 - val_loss: 0.8665 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8036 - loss: 0.8666 - val_accuracy: 0.7961 - val_loss: 0.8534 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8372 - loss: 0.8067 - val_accuracy: 0.8026 - val_loss: 0.8532 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8170 - loss: 0.8306 - val_accuracy: 0.7961 - val_loss: 0.8498 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 0.7933 - val_accuracy: 0.8158 - val_loss: 0.8454 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.8222 - val_accuracy: 0.8026 - val_loss: 0.8429 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.8402 - val_accuracy: 0.7895 - val_loss: 0.8404 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8068 - loss: 0.8210 - val_accuracy: 0.7961 - val_loss: 0.8383 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8332 - loss: 0.7899 - val_accuracy: 0.7961 - val_loss: 0.8417 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8139 - loss: 0.8668 - val_accuracy: 0.7895 - val_loss: 0.8321 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8305 - loss: 0.8050 - val_accuracy: 0.7961 - val_loss: 0.8286 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8176 - loss: 0.8499 - val_accuracy: 0.7829 - val_loss: 0.8313 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8466 - loss: 0.7680 - val_accuracy: 0.7829 - val_loss: 0.8293 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8359 - loss: 0.8176 - val_accuracy: 0.7763 - val_loss: 0.8279 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8156 - loss: 0.7892 - val_accuracy: 0.7895 - val_loss: 0.8284 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8542 - loss: 0.7587 - val_accuracy: 0.7829 - val_loss: 0.8225 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8434 - loss: 0.7616 - val_accuracy: 0.7829 - val_loss: 0.8205 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.7977 - val_accuracy: 0.7895 - val_loss: 0.8258 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8305 - loss: 0.7856 - val_accuracy: 0.7829 - val_loss: 0.8175 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8319 - loss: 0.7572 - val_accuracy: 0.7895 - val_loss: 0.8102 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8384 - loss: 0.7944 - val_accuracy: 0.8026 - val_loss: 0.8093 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8342 - loss: 0.7688 - val_accuracy: 0.8026 - val_loss: 0.8022 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8454 - loss: 0.7327 - val_accuracy: 0.7895 - val_loss: 0.8025 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8317 - loss: 0.7598 - val_accuracy: 0.7961 - val_loss: 0.7989 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8515 - loss: 0.7299 - val_accuracy: 0.7829 - val_loss: 0.7971 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8331 - loss: 0.7494 - val_accuracy: 0.7961 - val_loss: 0.7954 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8002 - loss: 0.7605 - val_accuracy: 0.7895 - val_loss: 0.7949 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8124 - loss: 0.7310 - val_accuracy: 0.7763 - val_loss: 0.7912 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8360 - loss: 0.7334 - val_accuracy: 0.7961 - val_loss: 0.7801 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8336 - loss: 0.7378 - val_accuracy: 0.7763 - val_loss: 0.7903 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 0.7155 - val_accuracy: 0.7763 - val_loss: 0.7942 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8248 - loss: 0.7347 - val_accuracy: 0.7829 - val_loss: 0.7906 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8243 - loss: 0.7334 - val_accuracy: 0.7895 - val_loss: 0.7715 - learning_rate: 5.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.7107 - val_accuracy: 0.7829 - val_loss: 0.7727 - learning_rate: 5.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8097 - loss: 0.7618 - val_accuracy: 0.7961 - val_loss: 0.7614 - learning_rate: 5.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8247 - loss: 0.7237 - val_accuracy: 0.7895 - val_loss: 0.7589 - learning_rate: 5.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8162 - loss: 0.7332 - val_accuracy: 0.7829 - val_loss: 0.7618 - learning_rate: 5.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 0.6957 - val_accuracy: 0.7895 - val_loss: 0.7685 - learning_rate: 5.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.7261 - val_accuracy: 0.8092 - val_loss: 0.7676 - learning_rate: 5.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8173 - loss: 0.7156 - val_accuracy: 0.8092 - val_loss: 0.7687 - learning_rate: 5.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8294 - loss: 0.6987 - val_accuracy: 0.7895 - val_loss: 0.7617 - learning_rate: 5.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8412 - loss: 0.7099 - val_accuracy: 0.7895 - val_loss: 0.7559 - learning_rate: 2.5000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8367 - loss: 0.6906 - val_accuracy: 0.7829 - val_loss: 0.7531 - learning_rate: 2.5000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8435 - loss: 0.6787 - val_accuracy: 0.8026 - val_loss: 0.7490 - learning_rate: 2.5000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8431 - loss: 0.6676 - val_accuracy: 0.8092 - val_loss: 0.7470 - learning_rate: 2.5000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8805 - loss: 0.6602 - val_accuracy: 0.7895 - val_loss: 0.7463 - learning_rate: 2.5000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8667 - loss: 0.6707 - val_accuracy: 0.7961 - val_loss: 0.7425 - learning_rate: 2.5000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8278 - loss: 0.7030 - val_accuracy: 0.8026 - val_loss: 0.7479 - learning_rate: 2.5000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8279 - loss: 0.6919 - val_accuracy: 0.7829 - val_loss: 0.7474 - learning_rate: 2.5000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8348 - loss: 0.6722 - val_accuracy: 0.7829 - val_loss: 0.7475 - learning_rate: 2.5000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8257 - loss: 0.6845 - val_accuracy: 0.7961 - val_loss: 0.7426 - learning_rate: 2.5000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8291 - loss: 0.6812 - val_accuracy: 0.7961 - val_loss: 0.7358 - learning_rate: 2.5000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8754 - loss: 0.6229 - val_accuracy: 0.8026 - val_loss: 0.7317 - learning_rate: 2.5000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8566 - loss: 0.6800 - val_accuracy: 0.7961 - val_loss: 0.7290 - learning_rate: 2.5000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8352 - loss: 0.6780 - val_accuracy: 0.7895 - val_loss: 0.7324 - learning_rate: 2.5000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8278 - loss: 0.6882 - val_accuracy: 0.7895 - val_loss: 0.7240 - learning_rate: 2.5000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8381 - loss: 0.6502 - val_accuracy: 0.7961 - val_loss: 0.7201 - learning_rate: 2.5000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8534 - loss: 0.6464 - val_accuracy: 0.7829 - val_loss: 0.7295 - learning_rate: 2.5000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8620 - loss: 0.6388 - val_accuracy: 0.7829 - val_loss: 0.7300 - learning_rate: 2.5000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8485 - loss: 0.6545 - val_accuracy: 0.7961 - val_loss: 0.7279 - learning_rate: 2.5000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8813 - loss: 0.6097 - val_accuracy: 0.7961 - val_loss: 0.7281 - learning_rate: 2.5000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8503 - loss: 0.6135 - val_accuracy: 0.7961 - val_loss: 0.7244 - learning_rate: 2.5000e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7923 - loss: 0.7535 \n",
            "✅ Improved Test Accuracy: 0.7961\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ===========================\n",
        "# Step 1: Train-Test Split\n",
        "# ===========================\n",
        "X = df_grouped.drop(columns=[\"Unnamed: 754_level_0\"])   # features\n",
        "y = df_grouped[\"Unnamed: 754_level_0\"]                  # target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "# Normalize the features (important for deep learning)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "]\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(512, activation=\"relu\", input_shape=(X_train_scaled.shape[1],),\n",
        "          kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(len(y.unique()), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"✅ Improved Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvC8jpJkcs2H"
      },
      "source": [
        "PCA 7 Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-TBB1mtffYf",
        "outputId": "61c4591a-06aa-4413-8079-700baca83852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3138093197.py:15: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  X = df.drop(columns=[\"Unnamed: 754_level_0\"])   # features\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'learning_rate': 0.2, 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best cross-validation accuracy: 0.8940633608815427\n",
            "\n",
            "Test Accuracy: 0.881578947368421\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.67      0.74        39\n",
            "           1       0.89      0.96      0.92       113\n",
            "\n",
            "    accuracy                           0.88       152\n",
            "   macro avg       0.87      0.81      0.83       152\n",
            "weighted avg       0.88      0.88      0.88       152\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 26  13]\n",
            " [  5 108]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ===========================\n",
        "# Step 1: Train-Test Split\n",
        "# ===========================\n",
        "X = df.drop(columns=[\"Unnamed: 754_level_0\"])   # features\n",
        "y = df[\"Unnamed: 754_level_0\"]                  # target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# ===========================\n",
        "# Step 2: Preprocessing on training data\n",
        "# ===========================\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)   # transform test with same scaler\n",
        "\n",
        "\n",
        "# Handle imbalance (SMOTE on train only)\n",
        "#smote = SMOTE(random_state=42)\n",
        "#X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected, y_train)\n",
        "\n",
        "#print(\"Before SMOTE:\", np.bincount(y_train))\n",
        "#print(\"After SMOTE:\", np.bincount(y_train_resampled))\n",
        "\n",
        "# ===========================\n",
        "# Step 3: Gradient Boosting + Hyperparameter Tuning\n",
        "# ===========================\n",
        "gbc = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=gbc,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid.best_score_)\n",
        "\n",
        "# ===========================\n",
        "# Step 4: Evaluate on test set\n",
        "# ===========================\n",
        "best_gbc = grid.best_estimator_\n",
        "\n",
        "y_pred = best_gbc.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI4mxohiQ5KH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g41Xb8f2QoDA",
        "outputId": "a290aac0-1b4c-414d-c324-e6e7ff76576d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4221517620.py:15: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.5268 - loss: 269321888.0000 - val_accuracy: 0.7934 - val_loss: 29392192.0000\n",
            "Epoch 2/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5970 - loss: 96416232.0000 - val_accuracy: 0.7934 - val_loss: 11719291.0000\n",
            "Epoch 3/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6058 - loss: 36933876.0000 - val_accuracy: 0.2066 - val_loss: 5051155.0000\n",
            "Epoch 4/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4900 - loss: 37704000.0000 - val_accuracy: 0.7934 - val_loss: 398376.5000\n",
            "Epoch 5/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5338 - loss: 23805022.0000 - val_accuracy: 0.7934 - val_loss: 563876.8750\n",
            "Epoch 6/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 11458049.0000 - val_accuracy: 0.7934 - val_loss: 98351.0859\n",
            "Epoch 7/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5854 - loss: 11794705.0000 - val_accuracy: 0.7934 - val_loss: 258312.7656\n",
            "Epoch 8/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6059 - loss: 5416479.0000 - val_accuracy: 0.7934 - val_loss: 184037.7188\n",
            "Epoch 9/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5696 - loss: 5498036.0000 - val_accuracy: 0.7934 - val_loss: 20744.6309\n",
            "Epoch 10/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5854 - loss: 3208694.2500 - val_accuracy: 0.2066 - val_loss: 6726.0063\n",
            "Epoch 11/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5622 - loss: 4027445.5000 - val_accuracy: 0.2066 - val_loss: 10527.7012\n",
            "Epoch 12/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 3156654.7500 - val_accuracy: 0.2066 - val_loss: 551.6457\n",
            "Epoch 13/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5809 - loss: 920837.4375 - val_accuracy: 0.7934 - val_loss: 24246.3438\n",
            "Epoch 14/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6397 - loss: 2821350.2500 - val_accuracy: 0.7934 - val_loss: 2565.7170\n",
            "Epoch 15/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5325 - loss: 1301640.5000 - val_accuracy: 0.7934 - val_loss: 18901.8145\n",
            "Epoch 16/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6521 - loss: 1881591.2500 - val_accuracy: 0.2066 - val_loss: 25740.9844\n",
            "Epoch 17/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5417 - loss: 2587283.7500 - val_accuracy: 0.7934 - val_loss: 18011.4141\n",
            "Epoch 18/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6158 - loss: 1538117.1250 - val_accuracy: 0.2066 - val_loss: 5407.8740\n",
            "Epoch 19/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5104 - loss: 1407156.3750 - val_accuracy: 0.7934 - val_loss: 13078.7148\n",
            "Epoch 20/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6765 - loss: 810863.7500 - val_accuracy: 0.7934 - val_loss: 8220.3242\n",
            "Epoch 21/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5502 - loss: 901599.8125 - val_accuracy: 0.2066 - val_loss: 45650.3633\n",
            "Epoch 22/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5883 - loss: 2075874.1250 - val_accuracy: 0.7934 - val_loss: 46378.0078\n",
            "Epoch 23/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6163 - loss: 1245213.3750 - val_accuracy: 0.7934 - val_loss: 4527.7437\n",
            "Epoch 24/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6610 - loss: 940031.5625 - val_accuracy: 0.7934 - val_loss: 13010.6904\n",
            "Epoch 25/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 1548128.3750 - val_accuracy: 0.7934 - val_loss: 1752.4835\n",
            "Epoch 26/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6139 - loss: 870078.8750 - val_accuracy: 0.7934 - val_loss: 3639.9421\n",
            "Epoch 27/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5766 - loss: 782951.4375 - val_accuracy: 0.2066 - val_loss: 2911.7480\n",
            "Epoch 28/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5864 - loss: 323226.5938 - val_accuracy: 0.7934 - val_loss: 7636.5640\n",
            "Epoch 29/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6036 - loss: 266333.3750 - val_accuracy: 0.2066 - val_loss: 4416.4546\n",
            "Epoch 30/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6096 - loss: 399059.6250 - val_accuracy: 0.7934 - val_loss: 2249.7935\n",
            "Epoch 31/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4986 - loss: 438702.0625 - val_accuracy: 0.7934 - val_loss: 17735.3906\n",
            "Epoch 32/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 553649.7500 - val_accuracy: 0.7934 - val_loss: 10648.5000\n",
            "Epoch 33/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6060 - loss: 297961.4062 - val_accuracy: 0.7934 - val_loss: 7879.3945\n",
            "Epoch 34/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5815 - loss: 598000.3125 - val_accuracy: 0.7934 - val_loss: 16980.9336\n",
            "Epoch 35/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5700 - loss: 225618.9219 - val_accuracy: 0.7934 - val_loss: 2116.3865\n",
            "Epoch 36/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6368 - loss: 440279.7812 - val_accuracy: 0.7934 - val_loss: 3663.7065\n",
            "Epoch 37/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6560 - loss: 275132.1875 - val_accuracy: 0.2066 - val_loss: 29346.9062\n",
            "Epoch 38/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5232 - loss: 591950.2500 - val_accuracy: 0.7934 - val_loss: 17639.4688\n",
            "Epoch 39/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5113 - loss: 246675.0000 - val_accuracy: 0.2066 - val_loss: 3332.0496\n",
            "Epoch 40/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5814 - loss: 147802.3906 - val_accuracy: 0.7934 - val_loss: 3218.8904\n",
            "Epoch 41/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5703 - loss: 243763.7812 - val_accuracy: 0.2066 - val_loss: 6662.3101\n",
            "Epoch 42/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5999 - loss: 191551.0469 - val_accuracy: 0.2066 - val_loss: 7844.1157\n",
            "Epoch 43/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5778 - loss: 170700.2500 - val_accuracy: 0.2066 - val_loss: 13011.3115\n",
            "Epoch 44/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6123 - loss: 113392.1562 - val_accuracy: 0.2066 - val_loss: 7161.1113\n",
            "Epoch 45/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5682 - loss: 240639.0156 - val_accuracy: 0.7934 - val_loss: 10127.3408\n",
            "Epoch 46/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6615 - loss: 252602.2188 - val_accuracy: 0.7934 - val_loss: 6655.7295\n",
            "Epoch 47/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6097 - loss: 161010.4219 - val_accuracy: 0.7934 - val_loss: 6611.1445\n",
            "Epoch 48/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7026 - loss: 88978.4297 - val_accuracy: 0.7934 - val_loss: 710.0723\n",
            "Epoch 49/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5885 - loss: 179127.9531 - val_accuracy: 0.7934 - val_loss: 6086.9648\n",
            "Epoch 50/50\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6015 - loss: 153231.8594 - val_accuracy: 0.7934 - val_loss: 10118.1348\n",
            "Test Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# =====================\n",
        "# 1. Load Reduced Dataset (7 features + class)\n",
        "# =====================\n",
        "\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
        "y = df[\"Unnamed: 754_level_0\"].values\n",
        "\n",
        "# Encode class labels (if categorical)\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)          # convert to numeric labels\n",
        "y = to_categorical(y)            # one-hot encode for NN\n",
        "\n",
        "# =====================\n",
        "# 2. Train-test split\n",
        "# =====================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# 3. Build Neural Network\n",
        "# =====================\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X.shape[1],)),  # input layer\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),                             # hidden layer\n",
        "    Dropout(0.3),\n",
        "    Dense(y.shape[1], activation='softmax')                   # output layer\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# =====================\n",
        "# 4. Train Model\n",
        "# =====================\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# 5. Evaluate Model\n",
        "# =====================\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FmXAPsDT5gU",
        "outputId": "17295c42-591c-4f0b-e9d5-fca5af570d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2088818468.py:15: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 284ms/step - accuracy: 0.4801 - loss: 12479387.0000 - val_accuracy: 0.7934 - val_loss: 1263667.6250\n",
            "Epoch 2/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 4021280.7500 - val_accuracy: 0.7934 - val_loss: 608778.5625\n",
            "Epoch 3/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6036 - loss: 2639260.2500 - val_accuracy: 0.7934 - val_loss: 285389.4062\n",
            "Epoch 4/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5279 - loss: 1554354.2500 - val_accuracy: 0.2066 - val_loss: 215107.6562\n",
            "Epoch 5/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5213 - loss: 1127019.6250 - val_accuracy: 0.7934 - val_loss: 165060.3125\n",
            "Epoch 6/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5848 - loss: 848488.0625 - val_accuracy: 0.2231 - val_loss: 16271.6416\n",
            "Epoch 7/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5165 - loss: 499546.4375 - val_accuracy: 0.7934 - val_loss: 42203.6445\n",
            "Epoch 8/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5635 - loss: 291605.0938 - val_accuracy: 0.2066 - val_loss: 113334.4141\n",
            "Epoch 9/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5265 - loss: 210461.3281 - val_accuracy: 0.7934 - val_loss: 11881.1914\n",
            "Epoch 10/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7047 - loss: 79809.4453 - val_accuracy: 0.7934 - val_loss: 0.6451\n",
            "Epoch 11/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6911 - loss: 17715.0703 - val_accuracy: 0.7934 - val_loss: 0.6395\n",
            "Epoch 12/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7119 - loss: 10609.1816 - val_accuracy: 0.7934 - val_loss: 0.6335\n",
            "Epoch 13/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6947 - loss: 1284.2960 - val_accuracy: 0.7934 - val_loss: 0.6278\n",
            "Epoch 14/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7137 - loss: 8323.6992 - val_accuracy: 0.7934 - val_loss: 0.6226\n",
            "Epoch 15/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7086 - loss: 1828.7687 - val_accuracy: 0.7934 - val_loss: 0.6176\n",
            "Epoch 16/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7348 - loss: 3595.9907 - val_accuracy: 0.7934 - val_loss: 0.6123\n",
            "Epoch 17/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7182 - loss: 533.9962 - val_accuracy: 0.7934 - val_loss: 0.6083\n",
            "Epoch 18/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7201 - loss: 331.8090 - val_accuracy: 0.7934 - val_loss: 0.6040\n",
            "Epoch 19/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7211 - loss: 293.1117 - val_accuracy: 0.7934 - val_loss: 0.5997\n",
            "Epoch 20/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7231 - loss: 505.1790 - val_accuracy: 0.7934 - val_loss: 0.5955\n",
            "Epoch 21/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7343 - loss: 125.0687 - val_accuracy: 0.7934 - val_loss: 0.5917\n",
            "Epoch 22/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7366 - loss: 120.8782 - val_accuracy: 0.7934 - val_loss: 0.5876\n",
            "Epoch 23/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7396 - loss: 302.5176 - val_accuracy: 0.7934 - val_loss: 0.5843\n",
            "Epoch 24/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7384 - loss: 495.7758 - val_accuracy: 0.7934 - val_loss: 0.5812\n",
            "Epoch 25/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7690 - loss: 361.6767 - val_accuracy: 0.7934 - val_loss: 0.5775\n",
            "Epoch 26/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7343 - loss: 1518.9017 - val_accuracy: 0.7934 - val_loss: 0.5742\n",
            "Epoch 27/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7212 - loss: 1552.2963 - val_accuracy: 0.7934 - val_loss: 0.5712\n",
            "Epoch 28/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7386 - loss: 375.3156 - val_accuracy: 0.7934 - val_loss: 0.5686\n",
            "Epoch 29/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7277 - loss: 22.9028 - val_accuracy: 0.7934 - val_loss: 0.5658\n",
            "Epoch 30/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7322 - loss: 0.5998 - val_accuracy: 0.7934 - val_loss: 0.5636\n",
            "Epoch 31/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7422 - loss: 313.3339 - val_accuracy: 0.7934 - val_loss: 0.5613\n",
            "Epoch 32/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7436 - loss: 44.0080 - val_accuracy: 0.7934 - val_loss: 0.5592\n",
            "Epoch 33/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6907 - loss: 34.0076 - val_accuracy: 0.7934 - val_loss: 0.5571\n",
            "Epoch 34/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7262 - loss: 37.2569 - val_accuracy: 0.7934 - val_loss: 0.5547\n",
            "Epoch 35/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6795 - loss: 17.5514 - val_accuracy: 0.7934 - val_loss: 0.5527\n",
            "Epoch 36/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7652 - loss: 342.8364 - val_accuracy: 0.7934 - val_loss: 0.5503\n",
            "Epoch 37/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7232 - loss: 48.4893 - val_accuracy: 0.7934 - val_loss: 0.5489\n",
            "Epoch 38/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7216 - loss: 1102.1503 - val_accuracy: 0.7934 - val_loss: 0.5472\n",
            "Epoch 39/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7025 - loss: 244.0557 - val_accuracy: 0.7934 - val_loss: 0.5458\n",
            "Epoch 40/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7340 - loss: 3788.5720 - val_accuracy: 0.7934 - val_loss: 0.5443\n",
            "Epoch 41/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7151 - loss: 597.5927 - val_accuracy: 0.7934 - val_loss: 0.5435\n",
            "Epoch 42/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7283 - loss: 0.5895 - val_accuracy: 0.7934 - val_loss: 0.5423\n",
            "Epoch 43/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7316 - loss: 0.5883 - val_accuracy: 0.7934 - val_loss: 0.5412\n",
            "Epoch 44/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7430 - loss: 0.5771 - val_accuracy: 0.7934 - val_loss: 0.5399\n",
            "Epoch 45/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7429 - loss: 102.9301 - val_accuracy: 0.7934 - val_loss: 0.5389\n",
            "Epoch 46/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7305 - loss: 6.7152 - val_accuracy: 0.7934 - val_loss: 0.5380\n",
            "Epoch 47/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7324 - loss: 0.5857 - val_accuracy: 0.7934 - val_loss: 0.5371\n",
            "Epoch 48/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7005 - loss: 36.8336 - val_accuracy: 0.7934 - val_loss: 0.5364\n",
            "Epoch 49/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7250 - loss: 380.0991 - val_accuracy: 0.7934 - val_loss: 0.5354\n",
            "Epoch 50/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7191 - loss: 0.5953 - val_accuracy: 0.7934 - val_loss: 0.5344\n",
            "Epoch 51/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7106 - loss: 27.6260 - val_accuracy: 0.7934 - val_loss: 0.5336\n",
            "Epoch 52/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7384 - loss: 16.2566 - val_accuracy: 0.7934 - val_loss: 0.5325\n",
            "Epoch 53/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7264 - loss: 473.9495 - val_accuracy: 0.7934 - val_loss: 0.5319\n",
            "Epoch 54/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7354 - loss: 18.5497 - val_accuracy: 0.7934 - val_loss: 0.5309\n",
            "Epoch 55/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7387 - loss: 41.1044 - val_accuracy: 0.7934 - val_loss: 0.5303\n",
            "Epoch 56/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7710 - loss: 0.5473 - val_accuracy: 0.7934 - val_loss: 0.5299\n",
            "Epoch 57/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7368 - loss: 34.4129 - val_accuracy: 0.7934 - val_loss: 0.5296\n",
            "Epoch 58/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7510 - loss: 0.5660 - val_accuracy: 0.7934 - val_loss: 0.5291\n",
            "Epoch 59/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7392 - loss: 30.0824 - val_accuracy: 0.7934 - val_loss: 0.5289\n",
            "Epoch 60/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7345 - loss: 648.7820 - val_accuracy: 0.7934 - val_loss: 0.5286\n",
            "Epoch 61/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7115 - loss: 802.0142 - val_accuracy: 0.7934 - val_loss: 0.5283\n",
            "Epoch 62/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7503 - loss: 8.6153 - val_accuracy: 0.7934 - val_loss: 0.5279\n",
            "Epoch 63/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7594 - loss: 0.5581 - val_accuracy: 0.7934 - val_loss: 0.5273\n",
            "Epoch 64/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7214 - loss: 0.5919 - val_accuracy: 0.7934 - val_loss: 0.5267\n",
            "Epoch 65/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7421 - loss: 0.5731 - val_accuracy: 0.7934 - val_loss: 0.5264\n",
            "Epoch 66/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7574 - loss: 2734.5234 - val_accuracy: 0.7934 - val_loss: 0.5263\n",
            "Epoch 67/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7537 - loss: 6671.6465 - val_accuracy: 0.7934 - val_loss: 0.5260\n",
            "Epoch 68/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7249 - loss: 129.4167 - val_accuracy: 0.7934 - val_loss: 0.5254\n",
            "Epoch 69/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6818 - loss: 524.4547 - val_accuracy: 0.7934 - val_loss: 0.5251\n",
            "Epoch 70/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7010 - loss: 3818.0708 - val_accuracy: 0.7934 - val_loss: 0.5246\n",
            "Epoch 71/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7418 - loss: 46.9494 - val_accuracy: 0.7934 - val_loss: 0.5241\n",
            "Epoch 72/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7375 - loss: 59.0535 - val_accuracy: 0.7934 - val_loss: 0.5239\n",
            "Epoch 73/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7316 - loss: 0.5818 - val_accuracy: 0.7934 - val_loss: 0.5234\n",
            "Epoch 74/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7011 - loss: 3105.4768 - val_accuracy: 0.7934 - val_loss: 0.5231\n",
            "Epoch 75/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7216 - loss: 0.8346 - val_accuracy: 0.7934 - val_loss: 0.5228\n",
            "Epoch 76/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7320 - loss: 0.5815 - val_accuracy: 0.7934 - val_loss: 0.5225\n",
            "Epoch 77/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7349 - loss: 0.7634 - val_accuracy: 0.7934 - val_loss: 0.5224\n",
            "Epoch 78/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7534 - loss: 0.5609 - val_accuracy: 0.7934 - val_loss: 0.5226\n",
            "Epoch 79/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7175 - loss: 0.5954 - val_accuracy: 0.7934 - val_loss: 0.5227\n",
            "Epoch 80/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7425 - loss: 0.5715 - val_accuracy: 0.7934 - val_loss: 0.5226\n",
            "Epoch 81/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7392 - loss: 0.5746 - val_accuracy: 0.7934 - val_loss: 0.5227\n",
            "Epoch 82/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7446 - loss: 0.5694 - val_accuracy: 0.7934 - val_loss: 0.5226\n",
            "Epoch 83/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7614 - loss: 1.1852 - val_accuracy: 0.7934 - val_loss: 0.5225\n",
            "Epoch 84/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7285 - loss: 0.5848 - val_accuracy: 0.7934 - val_loss: 0.5224\n",
            "Epoch 85/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6849 - loss: 12.8102 - val_accuracy: 0.7934 - val_loss: 0.5228\n",
            "Epoch 86/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6960 - loss: 0.6159 - val_accuracy: 0.7934 - val_loss: 0.5225\n",
            "Epoch 87/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7467 - loss: 0.5673 - val_accuracy: 0.7934 - val_loss: 0.5218\n",
            "Epoch 88/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7230 - loss: 752.8389 - val_accuracy: 0.7934 - val_loss: 0.5216\n",
            "Epoch 89/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7561 - loss: 0.5579 - val_accuracy: 0.7934 - val_loss: 0.5211\n",
            "Epoch 90/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6956 - loss: 0.6170 - val_accuracy: 0.7934 - val_loss: 0.5211\n",
            "Epoch 91/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7582 - loss: 0.5556 - val_accuracy: 0.7934 - val_loss: 0.5206\n",
            "Epoch 92/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7285 - loss: 1.7382 - val_accuracy: 0.7934 - val_loss: 0.5204\n",
            "Epoch 93/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.5595 - val_accuracy: 0.7934 - val_loss: 0.5203\n",
            "Epoch 94/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7335 - loss: 0.5795 - val_accuracy: 0.7934 - val_loss: 0.5204\n",
            "Epoch 95/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7117 - loss: 0.6014 - val_accuracy: 0.7934 - val_loss: 0.5202\n",
            "Epoch 96/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7229 - loss: 0.5904 - val_accuracy: 0.7934 - val_loss: 0.5199\n",
            "Epoch 97/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7177 - loss: 0.6288 - val_accuracy: 0.7934 - val_loss: 0.5196\n",
            "Epoch 98/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7285 - loss: 0.5848 - val_accuracy: 0.7934 - val_loss: 0.5193\n",
            "Epoch 99/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7009 - loss: 0.6113 - val_accuracy: 0.7934 - val_loss: 0.5191\n",
            "Epoch 100/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7398 - loss: 0.5733 - val_accuracy: 0.7934 - val_loss: 0.5188\n",
            "Test Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# =====================\n",
        "# 1. Load Reduced Dataset (7 features + class)\n",
        "# =====================\n",
        "\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
        "y = df[\"Unnamed: 754_level_0\"].values\n",
        "\n",
        "# Encode class labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "# =====================\n",
        "# 2. Train-test split\n",
        "# =====================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# 3. Build 10-Layer Neural Network\n",
        "# =====================\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X.shape[1],)),  # Layer 1 (input)\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation='relu'),  # Layer 2\n",
        "    Dense(64, activation='relu'),   # Layer 3\n",
        "    Dense(64, activation='relu'),   # Layer 4\n",
        "    Dense(32, activation='relu'),   # Layer 5\n",
        "    Dense(32, activation='relu'),   # Layer 6\n",
        "    Dense(16, activation='relu'),   # Layer 7\n",
        "    Dense(16, activation='relu'),   # Layer 8\n",
        "\n",
        "    Dropout(0.3),\n",
        "    Dense(y.shape[1], activation='softmax')  # Layer 9 (output)\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# =====================\n",
        "# 4. Train Model\n",
        "# =====================\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# 5. Evaluate\n",
        "# =====================\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWoXQeNbVkc9",
        "outputId": "0b97ba36-8c74-4476-c809-0cc2cfb636a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1934272307.py:14: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 301ms/step - accuracy: 0.3784 - loss: 445467.2188 - val_accuracy: 0.2066 - val_loss: 64416.6406\n",
            "Epoch 2/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4004 - loss: 41105.9766 - val_accuracy: 0.2066 - val_loss: 32032.0762\n",
            "Epoch 3/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4589 - loss: 50857.8008 - val_accuracy: 0.7934 - val_loss: 13054.0215\n",
            "Epoch 4/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6161 - loss: 34906.3164 - val_accuracy: 0.7934 - val_loss: 0.6562\n",
            "Epoch 5/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6706 - loss: 2392.3457 - val_accuracy: 0.7934 - val_loss: 0.6482\n",
            "Epoch 6/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7509 - loss: 0.6545 - val_accuracy: 0.7934 - val_loss: 0.6394\n",
            "Epoch 7/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7244 - loss: 0.6530 - val_accuracy: 0.7934 - val_loss: 0.6320\n",
            "Epoch 8/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7567 - loss: 0.6386 - val_accuracy: 0.7934 - val_loss: 0.6250\n",
            "Epoch 9/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7313 - loss: 0.6404 - val_accuracy: 0.7934 - val_loss: 0.6185\n",
            "Epoch 10/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7366 - loss: 0.6363 - val_accuracy: 0.7934 - val_loss: 0.6123\n",
            "Epoch 11/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7309 - loss: 0.6278 - val_accuracy: 0.7934 - val_loss: 0.6056\n",
            "Epoch 12/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7426 - loss: 0.6244 - val_accuracy: 0.7934 - val_loss: 0.6004\n",
            "Epoch 13/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7060 - loss: 0.6307 - val_accuracy: 0.7934 - val_loss: 0.5950\n",
            "Epoch 14/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7203 - loss: 0.6254 - val_accuracy: 0.7934 - val_loss: 0.5900\n",
            "Epoch 15/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7254 - loss: 0.6187 - val_accuracy: 0.7934 - val_loss: 0.5848\n",
            "Epoch 16/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7251 - loss: 0.6174 - val_accuracy: 0.7934 - val_loss: 0.5806\n",
            "Epoch 17/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7229 - loss: 0.6140 - val_accuracy: 0.7934 - val_loss: 0.5758\n",
            "Epoch 18/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.6078 - val_accuracy: 0.7934 - val_loss: 0.5713\n",
            "Epoch 19/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7392 - loss: 0.6014 - val_accuracy: 0.7934 - val_loss: 0.5675\n",
            "Epoch 20/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7575 - loss: 0.5891 - val_accuracy: 0.7934 - val_loss: 0.5641\n",
            "Epoch 21/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.5938 - val_accuracy: 0.7934 - val_loss: 0.5610\n",
            "Epoch 22/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7122 - loss: 0.6089 - val_accuracy: 0.7934 - val_loss: 0.5586\n",
            "Epoch 23/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7421 - loss: 0.5909 - val_accuracy: 0.7934 - val_loss: 0.5559\n",
            "Epoch 24/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7368 - loss: 0.5907 - val_accuracy: 0.7934 - val_loss: 0.5529\n",
            "Epoch 25/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7431 - loss: 0.5877 - val_accuracy: 0.7934 - val_loss: 0.5507\n",
            "Epoch 26/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7628 - loss: 0.5704 - val_accuracy: 0.7934 - val_loss: 0.5483\n",
            "Epoch 27/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7274 - loss: 0.5968 - val_accuracy: 0.7934 - val_loss: 0.5468\n",
            "Epoch 28/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7375 - loss: 0.5873 - val_accuracy: 0.7934 - val_loss: 0.5445\n",
            "Epoch 29/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7546 - loss: 0.5718 - val_accuracy: 0.7934 - val_loss: 0.5423\n",
            "Epoch 30/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7387 - loss: 0.5826 - val_accuracy: 0.7934 - val_loss: 0.5407\n",
            "Epoch 31/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7241 - loss: 0.5960 - val_accuracy: 0.7934 - val_loss: 0.5395\n",
            "Epoch 32/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7192 - loss: 0.5991 - val_accuracy: 0.7934 - val_loss: 0.5381\n",
            "Epoch 33/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7141 - loss: 0.6032 - val_accuracy: 0.7934 - val_loss: 0.5370\n",
            "Epoch 34/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7339 - loss: 0.5960 - val_accuracy: 0.7934 - val_loss: 0.5359\n",
            "Epoch 35/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6972 - loss: 0.6144 - val_accuracy: 0.7934 - val_loss: 0.5347\n",
            "Epoch 36/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7280 - loss: 0.5884 - val_accuracy: 0.7934 - val_loss: 0.5331\n",
            "Epoch 37/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7259 - loss: 0.5862 - val_accuracy: 0.7934 - val_loss: 0.5326\n",
            "Epoch 38/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7396 - loss: 0.5837 - val_accuracy: 0.7934 - val_loss: 0.5321\n",
            "Epoch 39/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7397 - loss: 0.5825 - val_accuracy: 0.7934 - val_loss: 0.5321\n",
            "Epoch 40/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7510 - loss: 0.5686 - val_accuracy: 0.7934 - val_loss: 0.5319\n",
            "Epoch 41/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7417 - loss: 0.5815 - val_accuracy: 0.7934 - val_loss: 0.5314\n",
            "Epoch 42/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7483 - loss: 0.5728 - val_accuracy: 0.7934 - val_loss: 0.5308\n",
            "Epoch 43/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6909 - loss: 0.6212 - val_accuracy: 0.7934 - val_loss: 0.5308\n",
            "Epoch 44/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7147 - loss: 0.5983 - val_accuracy: 0.7934 - val_loss: 0.5299\n",
            "Epoch 45/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7492 - loss: 0.5643 - val_accuracy: 0.7934 - val_loss: 0.5293\n",
            "Epoch 46/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7476 - loss: 0.5725 - val_accuracy: 0.7934 - val_loss: 0.5291\n",
            "Epoch 47/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7125 - loss: 0.5997 - val_accuracy: 0.7934 - val_loss: 0.5286\n",
            "Epoch 48/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7304 - loss: 0.5867 - val_accuracy: 0.7934 - val_loss: 0.5281\n",
            "Epoch 49/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7555 - loss: 0.5595 - val_accuracy: 0.7934 - val_loss: 0.5269\n",
            "Epoch 50/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7330 - loss: 0.5809 - val_accuracy: 0.7934 - val_loss: 0.5262\n",
            "Epoch 51/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7338 - loss: 0.5831 - val_accuracy: 0.7934 - val_loss: 0.5253\n",
            "Epoch 52/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7498 - loss: 0.5665 - val_accuracy: 0.7934 - val_loss: 0.5245\n",
            "Epoch 53/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7104 - loss: 0.6010 - val_accuracy: 0.7934 - val_loss: 0.5244\n",
            "Epoch 54/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7469 - loss: 0.5755 - val_accuracy: 0.7934 - val_loss: 0.5239\n",
            "Epoch 55/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7336 - loss: 0.5830 - val_accuracy: 0.7934 - val_loss: 0.5240\n",
            "Epoch 56/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7413 - loss: 0.5746 - val_accuracy: 0.7934 - val_loss: 0.5237\n",
            "Epoch 57/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7251 - loss: 0.5880 - val_accuracy: 0.7934 - val_loss: 0.5236\n",
            "Epoch 58/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7178 - loss: 0.5970 - val_accuracy: 0.7934 - val_loss: 0.5234\n",
            "Epoch 59/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7391 - loss: 0.5773 - val_accuracy: 0.7934 - val_loss: 0.5232\n",
            "Epoch 60/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7121 - loss: 0.6072 - val_accuracy: 0.7934 - val_loss: 0.5235\n",
            "Epoch 61/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7193 - loss: 0.5976 - val_accuracy: 0.7934 - val_loss: 0.5233\n",
            "Epoch 62/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7025 - loss: 0.6077 - val_accuracy: 0.7934 - val_loss: 0.5233\n",
            "Epoch 63/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7236 - loss: 0.5878 - val_accuracy: 0.7934 - val_loss: 0.5227\n",
            "Epoch 64/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7304 - loss: 0.5800 - val_accuracy: 0.7934 - val_loss: 0.5225\n",
            "Epoch 65/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7032 - loss: 0.6125 - val_accuracy: 0.7934 - val_loss: 0.5229\n",
            "Epoch 66/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7526 - loss: 0.5612 - val_accuracy: 0.7934 - val_loss: 0.5230\n",
            "Epoch 67/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7116 - loss: 0.6009 - val_accuracy: 0.7934 - val_loss: 0.5226\n",
            "Epoch 68/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7361 - loss: 0.5781 - val_accuracy: 0.7934 - val_loss: 0.5219\n",
            "Epoch 69/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7180 - loss: 0.5890 - val_accuracy: 0.7934 - val_loss: 0.5219\n",
            "Epoch 70/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7334 - loss: 0.5821 - val_accuracy: 0.7934 - val_loss: 0.5215\n",
            "Epoch 71/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7266 - loss: 0.5884 - val_accuracy: 0.7934 - val_loss: 0.5211\n",
            "Epoch 72/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7231 - loss: 0.5942 - val_accuracy: 0.7934 - val_loss: 0.5210\n",
            "Epoch 73/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.5879 - val_accuracy: 0.7934 - val_loss: 0.5205\n",
            "Epoch 74/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7552 - loss: 0.5561 - val_accuracy: 0.7934 - val_loss: 0.5204\n",
            "Epoch 75/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7353 - loss: 0.5758 - val_accuracy: 0.7934 - val_loss: 0.5201\n",
            "Epoch 76/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7234 - loss: 0.5940 - val_accuracy: 0.7934 - val_loss: 0.5204\n",
            "Epoch 77/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7173 - loss: 0.5938 - val_accuracy: 0.7934 - val_loss: 0.5205\n",
            "Epoch 78/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7263 - loss: 0.5948 - val_accuracy: 0.7934 - val_loss: 0.5209\n",
            "Epoch 79/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7335 - loss: 0.5818 - val_accuracy: 0.7934 - val_loss: 0.5208\n",
            "Epoch 80/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7156 - loss: 0.6038 - val_accuracy: 0.7934 - val_loss: 0.5209\n",
            "Epoch 81/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7316 - loss: 0.5816 - val_accuracy: 0.7934 - val_loss: 0.5214\n",
            "Epoch 82/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7104 - loss: 0.5999 - val_accuracy: 0.7934 - val_loss: 0.5219\n",
            "Epoch 83/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7364 - loss: 0.5801 - val_accuracy: 0.7934 - val_loss: 0.5218\n",
            "Epoch 84/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7168 - loss: 0.5952 - val_accuracy: 0.7934 - val_loss: 0.5219\n",
            "Epoch 85/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7452 - loss: 0.5697 - val_accuracy: 0.7934 - val_loss: 0.5217\n",
            "Epoch 86/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7195 - loss: 0.5914 - val_accuracy: 0.7934 - val_loss: 0.5212\n",
            "Epoch 87/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7422 - loss: 0.5713 - val_accuracy: 0.7934 - val_loss: 0.5207\n",
            "Epoch 88/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7371 - loss: 0.5765 - val_accuracy: 0.7934 - val_loss: 0.5210\n",
            "Epoch 89/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7092 - loss: 0.6091 - val_accuracy: 0.7934 - val_loss: 0.5211\n",
            "Epoch 90/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7183 - loss: 0.5955 - val_accuracy: 0.7934 - val_loss: 0.5213\n",
            "Epoch 91/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7224 - loss: 0.5970 - val_accuracy: 0.7934 - val_loss: 0.5211\n",
            "Epoch 92/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6851 - loss: 0.6363 - val_accuracy: 0.7934 - val_loss: 0.5213\n",
            "Epoch 93/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7395 - loss: 0.5756 - val_accuracy: 0.7934 - val_loss: 0.5210\n",
            "Epoch 94/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7286 - loss: 0.5889 - val_accuracy: 0.7934 - val_loss: 0.5210\n",
            "Epoch 95/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7261 - loss: 0.5803 - val_accuracy: 0.7934 - val_loss: 0.5205\n",
            "Epoch 96/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7032 - loss: 0.6078 - val_accuracy: 0.7934 - val_loss: 0.5202\n",
            "Epoch 97/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7237 - loss: 0.5837 - val_accuracy: 0.7934 - val_loss: 0.5201\n",
            "Epoch 98/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7107 - loss: 0.6068 - val_accuracy: 0.7934 - val_loss: 0.5207\n",
            "Epoch 99/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7452 - loss: 0.5713 - val_accuracy: 0.7934 - val_loss: 0.5215\n",
            "Epoch 100/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7346 - loss: 0.5784 - val_accuracy: 0.7934 - val_loss: 0.5213\n",
            "Epoch 101/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7278 - loss: 0.5845 - val_accuracy: 0.7934 - val_loss: 0.5212\n",
            "Epoch 102/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7363 - loss: 0.5775 - val_accuracy: 0.7934 - val_loss: 0.5210\n",
            "Epoch 103/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7565 - loss: 0.5567 - val_accuracy: 0.7934 - val_loss: 0.5210\n",
            "Epoch 104/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7271 - loss: 0.5863 - val_accuracy: 0.7934 - val_loss: 0.5210\n",
            "Epoch 105/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7499 - loss: 0.5648 - val_accuracy: 0.7934 - val_loss: 0.5206\n",
            "Epoch 106/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7094 - loss: 0.6044 - val_accuracy: 0.7934 - val_loss: 0.5208\n",
            "Epoch 107/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 0.5829 - val_accuracy: 0.7934 - val_loss: 0.5204\n",
            "Epoch 108/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7206 - loss: 0.6003 - val_accuracy: 0.7934 - val_loss: 0.5200\n",
            "Epoch 109/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7198 - loss: 0.5918 - val_accuracy: 0.7934 - val_loss: 0.5198\n",
            "Epoch 110/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7493 - loss: 0.5659 - val_accuracy: 0.7934 - val_loss: 0.5201\n",
            "Epoch 111/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7389 - loss: 0.5743 - val_accuracy: 0.7934 - val_loss: 0.5207\n",
            "Epoch 112/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7509 - loss: 0.5639 - val_accuracy: 0.7934 - val_loss: 0.5209\n",
            "Epoch 113/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7158 - loss: 0.5949 - val_accuracy: 0.7934 - val_loss: 0.5211\n",
            "Epoch 114/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7273 - loss: 0.5836 - val_accuracy: 0.7934 - val_loss: 0.5206\n",
            "Epoch 115/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7650 - loss: 0.5549 - val_accuracy: 0.7934 - val_loss: 0.5200\n",
            "Epoch 116/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7302 - loss: 0.5862 - val_accuracy: 0.7934 - val_loss: 0.5200\n",
            "Epoch 117/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7516 - loss: 0.5641 - val_accuracy: 0.7934 - val_loss: 0.5199\n",
            "Epoch 118/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7532 - loss: 0.5620 - val_accuracy: 0.7934 - val_loss: 0.5197\n",
            "Epoch 119/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7049 - loss: 0.6143 - val_accuracy: 0.7934 - val_loss: 0.5197\n",
            "Epoch 120/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7526 - loss: 0.5628 - val_accuracy: 0.7934 - val_loss: 0.5197\n",
            "Epoch 121/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7318 - loss: 0.5814 - val_accuracy: 0.7934 - val_loss: 0.5198\n",
            "Epoch 122/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7107 - loss: 0.6004 - val_accuracy: 0.7934 - val_loss: 0.5197\n",
            "Epoch 123/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7339 - loss: 0.5846 - val_accuracy: 0.7934 - val_loss: 0.5197\n",
            "Epoch 124/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7315 - loss: 0.5805 - val_accuracy: 0.7934 - val_loss: 0.5199\n",
            "Epoch 125/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7570 - loss: 0.5526 - val_accuracy: 0.7934 - val_loss: 0.5198\n",
            "Epoch 126/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7240 - loss: 0.5872 - val_accuracy: 0.7934 - val_loss: 0.5196\n",
            "Epoch 127/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7548 - loss: 0.5605 - val_accuracy: 0.7934 - val_loss: 0.5197\n",
            "Epoch 128/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7149 - loss: 0.6000 - val_accuracy: 0.7934 - val_loss: 0.5200\n",
            "Epoch 129/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7265 - loss: 0.5878 - val_accuracy: 0.7934 - val_loss: 0.5200\n",
            "Epoch 130/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7186 - loss: 0.5959 - val_accuracy: 0.7934 - val_loss: 0.5198\n",
            "Epoch 131/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7383 - loss: 0.5804 - val_accuracy: 0.7934 - val_loss: 0.5194\n",
            "Epoch 132/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7235 - loss: 0.5951 - val_accuracy: 0.7934 - val_loss: 0.5195\n",
            "Epoch 133/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7509 - loss: 0.5617 - val_accuracy: 0.7934 - val_loss: 0.5190\n",
            "Epoch 134/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7510 - loss: 0.5648 - val_accuracy: 0.7934 - val_loss: 0.5187\n",
            "Epoch 135/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7454 - loss: 0.5741 - val_accuracy: 0.7934 - val_loss: 0.5189\n",
            "Epoch 136/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7606 - loss: 0.5555 - val_accuracy: 0.7934 - val_loss: 0.5194\n",
            "Epoch 137/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7415 - loss: 0.5722 - val_accuracy: 0.7934 - val_loss: 0.5194\n",
            "Epoch 138/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7184 - loss: 0.6025 - val_accuracy: 0.7934 - val_loss: 0.5196\n",
            "Epoch 139/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7175 - loss: 0.6003 - val_accuracy: 0.7934 - val_loss: 0.5199\n",
            "Epoch 140/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7390 - loss: 0.5751 - val_accuracy: 0.7934 - val_loss: 0.5198\n",
            "Epoch 141/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7357 - loss: 0.5801 - val_accuracy: 0.7934 - val_loss: 0.5201\n",
            "Epoch 142/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7511 - loss: 0.5638 - val_accuracy: 0.7934 - val_loss: 0.5199\n",
            "Epoch 143/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7099 - loss: 0.6048 - val_accuracy: 0.7934 - val_loss: 0.5206\n",
            "Epoch 144/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7466 - loss: 0.5720 - val_accuracy: 0.7934 - val_loss: 0.5208\n",
            "Epoch 145/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7047 - loss: 0.6106 - val_accuracy: 0.7934 - val_loss: 0.5213\n",
            "Epoch 146/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7349 - loss: 0.5795 - val_accuracy: 0.7934 - val_loss: 0.5214\n",
            "Epoch 147/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7285 - loss: 0.5870 - val_accuracy: 0.7934 - val_loss: 0.5219\n",
            "Epoch 148/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7435 - loss: 0.5679 - val_accuracy: 0.7934 - val_loss: 0.5214\n",
            "Epoch 149/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7328 - loss: 0.5793 - val_accuracy: 0.7934 - val_loss: 0.5219\n",
            "Epoch 150/150\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7058 - loss: 0.6096 - val_accuracy: 0.7934 - val_loss: 0.5224\n",
            "Test Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# =====================\n",
        "# 1. Load Reduced Dataset (7 features + class)\n",
        "# =====================\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
        "y = df[\"Unnamed: 754_level_0\"].values\n",
        "\n",
        "# Encode class labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "# =====================\n",
        "# 2. Train-test split\n",
        "# =====================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# 3. Build 20-Layer Neural Network\n",
        "# =====================\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Dense(256, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Hidden layers (18 total, decreasing size)\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "\n",
        "# Dropout before output\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# =====================\n",
        "# 4. Train Model\n",
        "# =====================\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# 5. Evaluate\n",
        "# =====================\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhOTTXM8WXyG",
        "outputId": "9aa50ed5-a129-478c-e4de-f69d317b4903"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2351870246.py:15: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 507ms/step - accuracy: 0.7276 - loss: 1.7804 - val_accuracy: 0.7934 - val_loss: 0.6813\n",
            "Epoch 2/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7742 - loss: 0.6770 - val_accuracy: 0.7934 - val_loss: 0.6739\n",
            "Epoch 3/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7440 - loss: 0.6774 - val_accuracy: 0.7934 - val_loss: 0.6221\n",
            "Epoch 4/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7562 - loss: 0.6681 - val_accuracy: 0.7934 - val_loss: 0.6654\n",
            "Epoch 5/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7129 - loss: 0.6710 - val_accuracy: 0.7934 - val_loss: 0.6504\n",
            "Epoch 6/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7293 - loss: 0.6570 - val_accuracy: 0.7934 - val_loss: 0.6298\n",
            "Epoch 7/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7253 - loss: 0.6460 - val_accuracy: 0.7934 - val_loss: 0.6169\n",
            "Epoch 8/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7508 - loss: 0.6273 - val_accuracy: 0.7934 - val_loss: 0.5989\n",
            "Epoch 9/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7228 - loss: 0.6213 - val_accuracy: 0.7934 - val_loss: 0.5831\n",
            "Epoch 10/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7410 - loss: 0.6058 - val_accuracy: 0.7934 - val_loss: 0.5663\n",
            "Epoch 11/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7124 - loss: 0.6113 - val_accuracy: 0.7934 - val_loss: 0.5552\n",
            "Epoch 12/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7093 - loss: 0.6049 - val_accuracy: 0.7934 - val_loss: 0.5426\n",
            "Epoch 13/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7306 - loss: 0.5988 - val_accuracy: 0.7934 - val_loss: 0.5328\n",
            "Epoch 14/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7353 - loss: 0.5885 - val_accuracy: 0.7934 - val_loss: 0.5288\n",
            "Epoch 15/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7367 - loss: 0.5740 - val_accuracy: 0.7934 - val_loss: 0.5257\n",
            "Epoch 16/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7525 - loss: 0.5689 - val_accuracy: 0.7934 - val_loss: 0.5247\n",
            "Epoch 17/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6997 - loss: 0.6267 - val_accuracy: 0.7934 - val_loss: 0.5305\n",
            "Epoch 18/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7213 - loss: 0.6029 - val_accuracy: 0.7934 - val_loss: 0.5311\n",
            "Epoch 19/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7492 - loss: 0.5678 - val_accuracy: 0.7934 - val_loss: 0.5268\n",
            "Epoch 20/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7374 - loss: 0.5877 - val_accuracy: 0.7934 - val_loss: 0.5258\n",
            "Epoch 21/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7698 - loss: 0.5510 - val_accuracy: 0.7934 - val_loss: 0.5250\n",
            "Epoch 22/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7124 - loss: 0.6138 - val_accuracy: 0.7934 - val_loss: 0.5237\n",
            "Epoch 23/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7194 - loss: 0.6104 - val_accuracy: 0.7934 - val_loss: 0.5249\n",
            "Epoch 24/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7451 - loss: 0.5713 - val_accuracy: 0.7934 - val_loss: 0.5240\n",
            "Epoch 25/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7467 - loss: 0.5760 - val_accuracy: 0.7934 - val_loss: 0.5222\n",
            "Epoch 26/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7318 - loss: 0.5744 - val_accuracy: 0.7934 - val_loss: 0.5209\n",
            "Epoch 27/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7409 - loss: 0.5797 - val_accuracy: 0.7934 - val_loss: 0.5249\n",
            "Epoch 28/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7349 - loss: 0.5816 - val_accuracy: 0.7934 - val_loss: 0.5244\n",
            "Epoch 29/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7360 - loss: 0.5828 - val_accuracy: 0.7934 - val_loss: 0.5236\n",
            "Epoch 30/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7197 - loss: 0.6031 - val_accuracy: 0.7934 - val_loss: 0.5257\n",
            "Epoch 31/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7177 - loss: 0.6029 - val_accuracy: 0.7934 - val_loss: 0.5283\n",
            "Epoch 32/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7180 - loss: 0.5981 - val_accuracy: 0.7934 - val_loss: 0.5263\n",
            "Epoch 33/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7340 - loss: 0.5852 - val_accuracy: 0.7934 - val_loss: 0.5254\n",
            "Epoch 34/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7623 - loss: 0.5577 - val_accuracy: 0.7934 - val_loss: 0.5242\n",
            "Epoch 35/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7209 - loss: 0.5977 - val_accuracy: 0.7934 - val_loss: 0.5278\n",
            "Epoch 36/200\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7575 - loss: 0.5664 - val_accuracy: 0.7934 - val_loss: 0.5258\n",
            "Test Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# =====================\n",
        "# 1. Load Reduced Dataset (7 features + class)\n",
        "# =====================\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
        "y = df[\"Unnamed: 754_level_0\"].values\n",
        "\n",
        "# Encode class labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "# =====================\n",
        "# 2. Train-test split\n",
        "# =====================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# 3. Build 40-Layer Neural Network\n",
        "# =====================\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Dense(512, activation='relu', input_shape=(X.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Hidden layers (38 total)\n",
        "for units in [512, 512, 256, 256, 256,\n",
        "              128, 128, 128, 128, 128,\n",
        "              64, 64, 64, 64, 64,\n",
        "              32, 32, 32, 32, 32,\n",
        "              16, 16, 16, 16, 16,\n",
        "              16, 16, 16, 16, 16,\n",
        "              8, 8, 8, 8, 8, 8, 8, 8]:\n",
        "    model.add(Dense(units, activation='relu'))\n",
        "\n",
        "# Dropout before output\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# =====================\n",
        "# 4. Train Model with EarlyStopping\n",
        "# =====================\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# =====================\n",
        "# 5. Evaluate\n",
        "# =====================\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj8Mp-XJZt2U",
        "outputId": "b19c6a64-8b0b-4b36-ca99-f8ddb72fc17e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-855518625.py:21: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [21:48:54] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Accuracies:\n",
            "Logistic Regression: 0.8618\n",
            "Random Forest: 0.8684\n",
            "SVM: 0.8553\n",
            "XGBoost: 0.8947\n",
            "Neural Network: 0.9013\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ML models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# =====================\n",
        "# 1. Load dataset\n",
        "# =====================\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=[\"Unnamed: 754_level_0\"]).values\n",
        "y = df[\"Unnamed: 754_level_0\"].values\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Standardize features (important for SVM, Logistic, NN)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# =====================\n",
        "# 2. Logistic Regression\n",
        "# =====================\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred = log_reg.predict(X_test)\n",
        "acc_log = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# =====================\n",
        "# 3. Random Forest\n",
        "# =====================\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# =====================\n",
        "# 4. Support Vector Machine\n",
        "# =====================\n",
        "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "acc_svm = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# =====================\n",
        "# 5. XGBoost\n",
        "# =====================\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred = xgb.predict(X_test)\n",
        "acc_xgb = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# =====================\n",
        "# 6. Neural Network (Deep Learning)\n",
        "# =====================\n",
        "# One-hot encode target\n",
        "y_train_nn = to_categorical(y_train)\n",
        "y_test_nn = to_categorical(y_test)\n",
        "\n",
        "nn = Sequential()\n",
        "nn.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "nn.add(Dropout(0.3))\n",
        "nn.add(Dense(32, activation='relu'))\n",
        "nn.add(Dense(y_train_nn.shape[1], activation='softmax'))\n",
        "\n",
        "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "nn.fit(X_train, y_train_nn, validation_split=0.2, epochs=50, batch_size=16, verbose=0)\n",
        "\n",
        "loss, acc_nn = nn.evaluate(X_test, y_test_nn, verbose=0)\n",
        "\n",
        "# =====================\n",
        "# 7. Results\n",
        "# =====================\n",
        "results = {\n",
        "    \"Logistic Regression\": acc_log,\n",
        "    \"Random Forest\": acc_rf,\n",
        "    \"SVM\": acc_svm,\n",
        "    \"XGBoost\": acc_xgb,\n",
        "    \"Neural Network\": acc_nn\n",
        "}\n",
        "\n",
        "print(\"\\nModel Accuracies:\")\n",
        "for model, acc in results.items():\n",
        "    print(f\"{model}: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDyB_Iwza2z9",
        "outputId": "61e58b70-9907-4742-a3fb-5218f73aade8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 193ms/step - accuracy: 0.6475 - loss: 0.6811 - val_accuracy: 0.7934 - val_loss: 0.5345\n",
            "Epoch 2/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7401 - loss: 0.5621 - val_accuracy: 0.7934 - val_loss: 0.4920\n",
            "Epoch 3/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7407 - loss: 0.5115 - val_accuracy: 0.7934 - val_loss: 0.4639\n",
            "Epoch 4/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7645 - loss: 0.4638 - val_accuracy: 0.7934 - val_loss: 0.4776\n",
            "Epoch 5/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7191 - loss: 0.4379 - val_accuracy: 0.7934 - val_loss: 0.4224\n",
            "Epoch 6/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7268 - loss: 0.4842 - val_accuracy: 0.8430 - val_loss: 0.4008\n",
            "Epoch 7/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.3101 - val_accuracy: 0.8595 - val_loss: 0.4268\n",
            "Epoch 8/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8905 - loss: 0.2670 - val_accuracy: 0.8760 - val_loss: 0.4127\n",
            "Epoch 9/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9399 - loss: 0.2357 - val_accuracy: 0.8264 - val_loss: 0.4237\n",
            "Epoch 10/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9313 - loss: 0.2235 - val_accuracy: 0.8347 - val_loss: 0.4916\n",
            "Epoch 11/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9689 - loss: 0.1637 - val_accuracy: 0.8430 - val_loss: 0.6263\n",
            "Epoch 12/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9712 - loss: 0.1032 - val_accuracy: 0.8347 - val_loss: 0.6269\n",
            "Epoch 13/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.0901 - val_accuracy: 0.8512 - val_loss: 0.7161\n",
            "Epoch 14/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9777 - loss: 0.0916 - val_accuracy: 0.8512 - val_loss: 0.8289\n",
            "Epoch 15/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9737 - loss: 0.0858 - val_accuracy: 0.8595 - val_loss: 0.6627\n",
            "Epoch 16/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9526 - loss: 0.1596 - val_accuracy: 0.8595 - val_loss: 0.6078\n",
            "Epoch 17/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.0991 - val_accuracy: 0.8760 - val_loss: 0.6337\n",
            "Epoch 18/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0549 - val_accuracy: 0.8678 - val_loss: 0.5823\n",
            "Epoch 19/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0614 - val_accuracy: 0.8760 - val_loss: 0.7990\n",
            "Epoch 20/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.0851 - val_accuracy: 0.8512 - val_loss: 0.6926\n",
            "Epoch 21/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0481 - val_accuracy: 0.8595 - val_loss: 0.5436\n",
            "Epoch 22/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0328 - val_accuracy: 0.8926 - val_loss: 0.6018\n",
            "Epoch 23/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.0392 - val_accuracy: 0.9008 - val_loss: 0.7460\n",
            "Epoch 24/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 0.0170 - val_accuracy: 0.8843 - val_loss: 0.8762\n",
            "Epoch 25/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0143 - val_accuracy: 0.9091 - val_loss: 0.7864\n",
            "Epoch 26/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0208 - val_accuracy: 0.8926 - val_loss: 1.1317\n",
            "Epoch 27/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.0143 - val_accuracy: 0.8926 - val_loss: 0.9495\n",
            "Epoch 28/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0064 - val_accuracy: 0.9008 - val_loss: 0.9998\n",
            "Epoch 29/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0256 - val_accuracy: 0.9008 - val_loss: 1.1782\n",
            "Epoch 30/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0057 - val_accuracy: 0.9008 - val_loss: 1.1580\n",
            "Epoch 31/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0255 - val_accuracy: 0.9008 - val_loss: 1.1169\n",
            "Epoch 32/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.8926 - val_loss: 1.2098\n",
            "Epoch 33/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0050 - val_accuracy: 0.8760 - val_loss: 1.2187\n",
            "Epoch 34/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0373 - val_accuracy: 0.8926 - val_loss: 1.1830\n",
            "Epoch 35/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0140 - val_accuracy: 0.8760 - val_loss: 1.1044\n",
            "Epoch 36/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9802 - loss: 0.1010 - val_accuracy: 0.9091 - val_loss: 0.6337\n",
            "Epoch 37/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0066 - val_accuracy: 0.9091 - val_loss: 0.8528\n",
            "Epoch 38/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.8926 - val_loss: 1.0137\n",
            "Epoch 39/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9008 - val_loss: 0.9077\n",
            "Epoch 40/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9008 - val_loss: 1.3122\n",
            "Epoch 41/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9008 - val_loss: 1.6474\n",
            "Epoch 42/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0060 - val_accuracy: 0.8926 - val_loss: 1.1472\n",
            "Epoch 43/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8926 - val_loss: 1.3026\n",
            "Epoch 44/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9008 - val_loss: 1.4676\n",
            "Epoch 45/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9091 - val_loss: 1.4788\n",
            "Epoch 46/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9091 - val_loss: 1.5779\n",
            "Epoch 47/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.9215e-04 - val_accuracy: 0.9174 - val_loss: 1.6354\n",
            "Epoch 48/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.3650e-04 - val_accuracy: 0.9174 - val_loss: 1.5542\n",
            "Epoch 49/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.5619e-04 - val_accuracy: 0.9174 - val_loss: 1.5692\n",
            "Epoch 50/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.2921e-04 - val_accuracy: 0.9174 - val_loss: 1.6071\n",
            "Epoch 51/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6328e-04 - val_accuracy: 0.9174 - val_loss: 1.6387\n",
            "Epoch 52/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4792e-04 - val_accuracy: 0.9174 - val_loss: 1.6421\n",
            "Epoch 53/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.9566e-04 - val_accuracy: 0.9174 - val_loss: 1.6452\n",
            "Epoch 54/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0044 - val_accuracy: 0.9174 - val_loss: 2.5090\n",
            "Epoch 55/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0100 - val_accuracy: 0.9174 - val_loss: 2.0771\n",
            "Epoch 56/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9834 - loss: 0.1938 - val_accuracy: 0.8512 - val_loss: 0.4344\n",
            "Epoch 57/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9265 - loss: 0.1449 - val_accuracy: 0.8678 - val_loss: 0.4383\n",
            "Epoch 58/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0509 - val_accuracy: 0.8843 - val_loss: 0.6532\n",
            "Epoch 59/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9783 - loss: 0.0363 - val_accuracy: 0.8678 - val_loss: 0.5971\n",
            "Epoch 60/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0196 - val_accuracy: 0.9174 - val_loss: 0.9739\n",
            "Epoch 61/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0176 - val_accuracy: 0.9174 - val_loss: 1.0148\n",
            "Epoch 62/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0185 - val_accuracy: 0.8926 - val_loss: 1.0069\n",
            "Epoch 63/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9873 - loss: 0.0273 - val_accuracy: 0.9091 - val_loss: 1.2868\n",
            "Epoch 64/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0282 - val_accuracy: 0.9091 - val_loss: 0.9595\n",
            "Epoch 65/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0047 - val_accuracy: 0.9008 - val_loss: 0.8878\n",
            "Epoch 66/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0138 - val_accuracy: 0.9008 - val_loss: 1.0299\n",
            "Epoch 67/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9091 - val_loss: 1.1972\n",
            "Epoch 68/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0306 - val_accuracy: 0.8926 - val_loss: 0.7686\n",
            "Epoch 69/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0205 - val_accuracy: 0.8760 - val_loss: 0.5256\n",
            "Epoch 70/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8926 - val_loss: 0.6895\n",
            "Epoch 71/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0033 - val_accuracy: 0.8926 - val_loss: 0.8873\n",
            "Epoch 72/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8926 - val_loss: 1.0140\n",
            "Epoch 73/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8926 - val_loss: 1.0626\n",
            "Epoch 74/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0461 - val_accuracy: 0.9008 - val_loss: 1.1146\n",
            "Epoch 75/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9174 - val_loss: 1.0666\n",
            "Epoch 76/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9174 - val_loss: 1.0201\n",
            "Epoch 77/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.8995e-04 - val_accuracy: 0.9174 - val_loss: 1.0552\n",
            "Epoch 78/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.0111e-04 - val_accuracy: 0.9174 - val_loss: 1.1231\n",
            "Epoch 79/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9174 - val_loss: 1.2305\n",
            "Epoch 80/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9174 - val_loss: 1.2736\n",
            "Epoch 81/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.0978e-04 - val_accuracy: 0.9174 - val_loss: 1.1288\n",
            "Epoch 82/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 8.8047e-04 - val_accuracy: 0.9174 - val_loss: 1.4249\n",
            "Epoch 83/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.9091 - val_loss: 1.4613\n",
            "Epoch 84/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4253e-04 - val_accuracy: 0.9091 - val_loss: 1.3595\n",
            "Epoch 85/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8843 - val_loss: 1.3249\n",
            "Epoch 86/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.1503e-04 - val_accuracy: 0.8843 - val_loss: 1.3624\n",
            "Epoch 87/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5231e-04 - val_accuracy: 0.8926 - val_loss: 1.4150\n",
            "Epoch 88/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.6237e-04 - val_accuracy: 0.9008 - val_loss: 1.5812\n",
            "Epoch 89/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0051 - val_accuracy: 0.9008 - val_loss: 1.9692\n",
            "Epoch 90/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9091 - val_loss: 1.9418\n",
            "Epoch 91/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0068 - val_accuracy: 0.9174 - val_loss: 1.9481\n",
            "Epoch 92/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8926 - val_loss: 2.0889\n",
            "Epoch 93/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.9201e-04 - val_accuracy: 0.8843 - val_loss: 1.9561\n",
            "Epoch 94/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.0562 - val_accuracy: 0.8760 - val_loss: 0.8954\n",
            "Epoch 95/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0779 - val_accuracy: 0.8843 - val_loss: 0.6571\n",
            "Epoch 96/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.8678 - val_loss: 1.4544\n",
            "Epoch 97/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8760 - val_loss: 1.5858\n",
            "Epoch 98/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0022 - val_accuracy: 0.8678 - val_loss: 1.6314\n",
            "Epoch 99/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.6184e-04 - val_accuracy: 0.8678 - val_loss: 1.7987\n",
            "Epoch 100/100\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4238e-04 - val_accuracy: 0.8678 - val_loss: 1.8593\n",
            "\n",
            "Neural Network (10 hidden layers) Accuracy: 0.9079\n"
          ]
        }
      ],
      "source": [
        "# =====================\n",
        "# Neural Network (Deep Learning) with 10 Hidden Layers\n",
        "# =====================\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# One-hot encode target\n",
        "y_train_nn = to_categorical(y_train)\n",
        "y_test_nn = to_categorical(y_test)\n",
        "\n",
        "nn = Sequential()\n",
        "nn.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "# Add 10 hidden layers\n",
        "for _ in range(10):\n",
        "    nn.add(Dense(64, activation='relu'))\n",
        "    nn.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(y_train_nn.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile\n",
        "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "nn.fit(X_train, y_train_nn, validation_split=0.2, epochs=100, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "loss, acc_nn = nn.evaluate(X_test, y_test_nn, verbose=0)\n",
        "print(f\"\\nNeural Network (10 hidden layers) Accuracy: {acc_nn:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWG31_G0b_Kj",
        "outputId": "a7c13bd3-5c08-4b18-c5a5-d014dbe75a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 262ms/step - accuracy: 0.5431 - loss: 0.9985 - val_accuracy: 0.7934 - val_loss: 0.5901 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5111 - loss: 1.0187 - val_accuracy: 0.7934 - val_loss: 0.5437 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5402 - loss: 0.9026 - val_accuracy: 0.7934 - val_loss: 0.5238 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5655 - loss: 0.8312 - val_accuracy: 0.7934 - val_loss: 0.5111 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6297 - loss: 0.7102 - val_accuracy: 0.7934 - val_loss: 0.5128 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6531 - loss: 0.7886 - val_accuracy: 0.7934 - val_loss: 0.5136 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6623 - loss: 0.7611 - val_accuracy: 0.7934 - val_loss: 0.5201 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6863 - loss: 0.6732 - val_accuracy: 0.7934 - val_loss: 0.5178 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6489 - loss: 0.6976 - val_accuracy: 0.7934 - val_loss: 0.5105 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6624 - loss: 0.7113 - val_accuracy: 0.7934 - val_loss: 0.5142 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6486 - loss: 0.7341 - val_accuracy: 0.7934 - val_loss: 0.5129 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6924 - loss: 0.6465 - val_accuracy: 0.7934 - val_loss: 0.5112 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6984 - loss: 0.6501 - val_accuracy: 0.7934 - val_loss: 0.5135 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6826 - loss: 0.6920 - val_accuracy: 0.7934 - val_loss: 0.5143 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7324 - loss: 0.6187 - val_accuracy: 0.7934 - val_loss: 0.5121 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7161 - loss: 0.6261 - val_accuracy: 0.7934 - val_loss: 0.5135 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7245 - loss: 0.6003 - val_accuracy: 0.7934 - val_loss: 0.5191 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6535 - loss: 0.6660 - val_accuracy: 0.7934 - val_loss: 0.5175 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6873 - loss: 0.6265 - val_accuracy: 0.7934 - val_loss: 0.5183 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7297 - loss: 0.5944 - val_accuracy: 0.7934 - val_loss: 0.5170 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7049 - loss: 0.6334 - val_accuracy: 0.7934 - val_loss: 0.5109 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7130 - loss: 0.6120 - val_accuracy: 0.7934 - val_loss: 0.5078 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6887 - loss: 0.6340 - val_accuracy: 0.7934 - val_loss: 0.5077 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6927 - loss: 0.6306 - val_accuracy: 0.7934 - val_loss: 0.5079 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7344 - loss: 0.5848 - val_accuracy: 0.7934 - val_loss: 0.5080 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7205 - loss: 0.6018 - val_accuracy: 0.7934 - val_loss: 0.5099 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7017 - loss: 0.6071 - val_accuracy: 0.7934 - val_loss: 0.5132 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6953 - loss: 0.6009 - val_accuracy: 0.7934 - val_loss: 0.5156 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7038 - loss: 0.5969 - val_accuracy: 0.7934 - val_loss: 0.5129 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7268 - loss: 0.5762 - val_accuracy: 0.7934 - val_loss: 0.5148 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7423 - loss: 0.5779 - val_accuracy: 0.7934 - val_loss: 0.5144 - learning_rate: 2.5000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7343 - loss: 0.5837 - val_accuracy: 0.7934 - val_loss: 0.5130 - learning_rate: 2.5000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7275 - loss: 0.6076 - val_accuracy: 0.7934 - val_loss: 0.5129 - learning_rate: 2.5000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7226 - loss: 0.6021 - val_accuracy: 0.7934 - val_loss: 0.5131 - learning_rate: 2.5000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7186 - loss: 0.6312 - val_accuracy: 0.7934 - val_loss: 0.5142 - learning_rate: 2.5000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7175 - loss: 0.6354 - val_accuracy: 0.7934 - val_loss: 0.5153 - learning_rate: 2.5000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6971 - loss: 0.6081 - val_accuracy: 0.7934 - val_loss: 0.5156 - learning_rate: 2.5000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7257 - loss: 0.6078 - val_accuracy: 0.7934 - val_loss: 0.5166 - learning_rate: 1.2500e-04\n",
            "\n",
            "Improved Neural Network (10 hidden layers) Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# One-hot encode target\n",
        "y_train_nn = to_categorical(y_train)\n",
        "y_test_nn = to_categorical(y_test)\n",
        "\n",
        "nn = Sequential()\n",
        "nn.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "nn.add(BatchNormalization())\n",
        "nn.add(Dropout(0.3))\n",
        "\n",
        "# Add 10 hidden layers\n",
        "for _ in range(10):\n",
        "    nn.add(Dense(64, activation='relu'))\n",
        "    nn.add(BatchNormalization())\n",
        "    nn.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(y_train_nn.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile\n",
        "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6)\n",
        "\n",
        "# Train\n",
        "history = nn.fit(\n",
        "    X_train, y_train_nn,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc_nn = nn.evaluate(X_test, y_test_nn, verbose=0)\n",
        "print(f\"\\nImproved Neural Network (10 hidden layers) Accuracy: {acc_nn:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adwzyWd4fUV1",
        "outputId": "5459cb5b-cf05-49a7-d0d7-9473b0ab9f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 745_level_0_tqwt_kurtosisValue_dec_28',\n",
            "       'Unnamed: 746_level_0_tqwt_kurtosisValue_dec_29',\n",
            "       'Unnamed: 747_level_0_tqwt_kurtosisValue_dec_30',\n",
            "       'Unnamed: 748_level_0_tqwt_kurtosisValue_dec_31',\n",
            "       'Unnamed: 749_level_0_tqwt_kurtosisValue_dec_32',\n",
            "       'Unnamed: 750_level_0_tqwt_kurtosisValue_dec_33',\n",
            "       'Unnamed: 751_level_0_tqwt_kurtosisValue_dec_34',\n",
            "       'Unnamed: 752_level_0_tqwt_kurtosisValue_dec_35',\n",
            "       'Unnamed: 753_level_0_tqwt_kurtosisValue_dec_36',\n",
            "       'Unnamed: 754_level_0_class'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in df.columns]\n",
        "print(df.columns[-10:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KwI6ZxTMy2l",
        "outputId": "fd0cc68c-fc26-4c16-dbb6-f08c401d0fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (756, 755)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 756 entries, 0 to 755\n",
            "Columns: 755 entries, Unnamed: 0_level_0_id to Unnamed: 754_level_0_class\n",
            "dtypes: float64(749), int64(6)\n",
            "memory usage: 4.4 MB\n",
            "None\n",
            "___________________________\n",
            "\n",
            "       Unnamed: 0_level_0_id  Unnamed: 1_level_0_gender  \\\n",
            "count             756.000000                 756.000000   \n",
            "mean              125.500000                   0.515873   \n",
            "std                72.793721                   0.500079   \n",
            "min                 0.000000                   0.000000   \n",
            "25%                62.750000                   0.000000   \n",
            "50%               125.500000                   1.000000   \n",
            "75%               188.250000                   1.000000   \n",
            "max               251.000000                   1.000000   \n",
            "\n",
            "       Baseline Features_PPE  Unnamed: 3_level_0_DFA  Unnamed: 4_level_0_RPDE  \\\n",
            "count             756.000000              756.000000               756.000000   \n",
            "mean                0.746284                0.700414                 0.489058   \n",
            "std                 0.169294                0.069718                 0.137442   \n",
            "min                 0.041551                0.543500                 0.154300   \n",
            "25%                 0.762833                0.647053                 0.386537   \n",
            "50%                 0.809655                0.700525                 0.484355   \n",
            "75%                 0.834315                0.754985                 0.586515   \n",
            "max                 0.907660                0.852640                 0.871230   \n",
            "\n",
            "       Unnamed: 5_level_0_numPulses  Unnamed: 6_level_0_numPeriodsPulses  \\\n",
            "count                    756.000000                           756.000000   \n",
            "mean                     323.972222                           322.678571   \n",
            "std                       99.219059                            99.402499   \n",
            "min                        2.000000                             1.000000   \n",
            "25%                      251.000000                           250.000000   \n",
            "50%                      317.000000                           316.000000   \n",
            "75%                      384.250000                           383.250000   \n",
            "max                      907.000000                           905.000000   \n",
            "\n",
            "       Unnamed: 7_level_0_meanPeriodPulses  \\\n",
            "count                           756.000000   \n",
            "mean                              0.006360   \n",
            "std                               0.001826   \n",
            "min                               0.002107   \n",
            "25%                               0.005003   \n",
            "50%                               0.006048   \n",
            "75%                               0.007528   \n",
            "max                               0.012966   \n",
            "\n",
            "       Unnamed: 8_level_0_stdDevPeriodPulses  Unnamed: 9_level_0_locPctJitter  \\\n",
            "count                             756.000000                       756.000000   \n",
            "mean                                0.000383                         0.002324   \n",
            "std                                 0.000728                         0.002628   \n",
            "min                                 0.000011                         0.000210   \n",
            "25%                                 0.000049                         0.000970   \n",
            "50%                                 0.000077                         0.001495   \n",
            "75%                                 0.000171                         0.002520   \n",
            "max                                 0.003483                         0.027750   \n",
            "\n",
            "       ...  Unnamed: 745_level_0_tqwt_kurtosisValue_dec_28  \\\n",
            "count  ...                                      756.000000   \n",
            "mean   ...                                       26.237251   \n",
            "std    ...                                       42.220693   \n",
            "min    ...                                        1.509800   \n",
            "25%    ...                                        2.408675   \n",
            "50%    ...                                        5.586300   \n",
            "75%    ...                                       28.958075   \n",
            "max    ...                                      239.788800   \n",
            "\n",
            "       Unnamed: 746_level_0_tqwt_kurtosisValue_dec_29  \\\n",
            "count                                      756.000000   \n",
            "mean                                        22.840337   \n",
            "std                                         32.626464   \n",
            "min                                          1.531700   \n",
            "25%                                          3.452800   \n",
            "50%                                          7.062750   \n",
            "75%                                         29.830850   \n",
            "max                                        203.311300   \n",
            "\n",
            "       Unnamed: 747_level_0_tqwt_kurtosisValue_dec_30  \\\n",
            "count                                      756.000000   \n",
            "mean                                        18.587888   \n",
            "std                                         25.537464   \n",
            "min                                          1.582900   \n",
            "25%                                          3.354825   \n",
            "50%                                          6.077400   \n",
            "75%                                         21.944050   \n",
            "max                                        121.542900   \n",
            "\n",
            "       Unnamed: 748_level_0_tqwt_kurtosisValue_dec_31  \\\n",
            "count                                      756.000000   \n",
            "mean                                        13.872018   \n",
            "std                                         20.046029   \n",
            "min                                          1.747200   \n",
            "25%                                          3.077450   \n",
            "50%                                          4.770850   \n",
            "75%                                         13.188000   \n",
            "max                                        102.207000   \n",
            "\n",
            "       Unnamed: 749_level_0_tqwt_kurtosisValue_dec_32  \\\n",
            "count                                      756.000000   \n",
            "mean                                        12.218953   \n",
            "std                                         17.783642   \n",
            "min                                          1.789500   \n",
            "25%                                          2.937025   \n",
            "50%                                          4.300450   \n",
            "75%                                         10.876150   \n",
            "max                                         85.571700   \n",
            "\n",
            "       Unnamed: 750_level_0_tqwt_kurtosisValue_dec_33  \\\n",
            "count                                      756.000000   \n",
            "mean                                        12.375335   \n",
            "std                                         16.341665   \n",
            "min                                          1.628700   \n",
            "25%                                          3.114375   \n",
            "50%                                          4.741450   \n",
            "75%                                         12.201325   \n",
            "max                                         73.532200   \n",
            "\n",
            "       Unnamed: 751_level_0_tqwt_kurtosisValue_dec_34  \\\n",
            "count                                      756.000000   \n",
            "mean                                        14.799230   \n",
            "std                                         15.722502   \n",
            "min                                          1.861700   \n",
            "25%                                          3.665925   \n",
            "50%                                          6.725700   \n",
            "75%                                         21.922050   \n",
            "max                                         62.007300   \n",
            "\n",
            "       Unnamed: 752_level_0_tqwt_kurtosisValue_dec_35  \\\n",
            "count                                      756.000000   \n",
            "mean                                        14.751559   \n",
            "std                                         14.432979   \n",
            "min                                          1.955900   \n",
            "25%                                          3.741275   \n",
            "50%                                          7.334250   \n",
            "75%                                         22.495175   \n",
            "max                                         57.544300   \n",
            "\n",
            "       Unnamed: 753_level_0_tqwt_kurtosisValue_dec_36  \\\n",
            "count                                      756.000000   \n",
            "mean                                        31.481110   \n",
            "std                                         34.230991   \n",
            "min                                          2.364000   \n",
            "25%                                          3.948750   \n",
            "50%                                         10.637250   \n",
            "75%                                         61.125325   \n",
            "max                                        156.423700   \n",
            "\n",
            "       Unnamed: 754_level_0_class  \n",
            "count                  756.000000  \n",
            "mean                     0.746032  \n",
            "std                      0.435568  \n",
            "min                      0.000000  \n",
            "25%                      0.000000  \n",
            "50%                      1.000000  \n",
            "75%                      1.000000  \n",
            "max                      1.000000  \n",
            "\n",
            "[8 rows x 755 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"shape:\", df.shape)\n",
        "print(df.info())\n",
        "print(\"___________________________\\n\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "NFO181m4OAH_",
        "outputId": "72558e42-0395-4d97-d447-76e2bf442a8a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e052971a-043b-4ba5-b7fd-f5bb38f19b32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0_level_0_id</th>\n",
              "      <th>Unnamed: 1_level_0_gender</th>\n",
              "      <th>Baseline Features_PPE</th>\n",
              "      <th>Unnamed: 3_level_0_DFA</th>\n",
              "      <th>Unnamed: 4_level_0_RPDE</th>\n",
              "      <th>Unnamed: 5_level_0_numPulses</th>\n",
              "      <th>Unnamed: 6_level_0_numPeriodsPulses</th>\n",
              "      <th>Unnamed: 7_level_0_meanPeriodPulses</th>\n",
              "      <th>Unnamed: 8_level_0_stdDevPeriodPulses</th>\n",
              "      <th>Unnamed: 9_level_0_locPctJitter</th>\n",
              "      <th>...</th>\n",
              "      <th>Unnamed: 745_level_0_tqwt_kurtosisValue_dec_28</th>\n",
              "      <th>Unnamed: 746_level_0_tqwt_kurtosisValue_dec_29</th>\n",
              "      <th>Unnamed: 747_level_0_tqwt_kurtosisValue_dec_30</th>\n",
              "      <th>Unnamed: 748_level_0_tqwt_kurtosisValue_dec_31</th>\n",
              "      <th>Unnamed: 749_level_0_tqwt_kurtosisValue_dec_32</th>\n",
              "      <th>Unnamed: 750_level_0_tqwt_kurtosisValue_dec_33</th>\n",
              "      <th>Unnamed: 751_level_0_tqwt_kurtosisValue_dec_34</th>\n",
              "      <th>Unnamed: 752_level_0_tqwt_kurtosisValue_dec_35</th>\n",
              "      <th>Unnamed: 753_level_0_tqwt_kurtosisValue_dec_36</th>\n",
              "      <th>Unnamed: 754_level_0_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.85247</td>\n",
              "      <td>0.71826</td>\n",
              "      <td>0.57227</td>\n",
              "      <td>240</td>\n",
              "      <td>239</td>\n",
              "      <td>0.008064</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.00218</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5620</td>\n",
              "      <td>2.6445</td>\n",
              "      <td>3.8686</td>\n",
              "      <td>4.2105</td>\n",
              "      <td>5.1221</td>\n",
              "      <td>4.4625</td>\n",
              "      <td>2.6202</td>\n",
              "      <td>3.0004</td>\n",
              "      <td>18.9405</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76686</td>\n",
              "      <td>0.69481</td>\n",
              "      <td>0.53966</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>0.008258</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.00195</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5589</td>\n",
              "      <td>3.6107</td>\n",
              "      <td>23.5155</td>\n",
              "      <td>14.1962</td>\n",
              "      <td>11.0261</td>\n",
              "      <td>9.5082</td>\n",
              "      <td>6.5245</td>\n",
              "      <td>6.3431</td>\n",
              "      <td>45.1780</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.85083</td>\n",
              "      <td>0.67604</td>\n",
              "      <td>0.58982</td>\n",
              "      <td>232</td>\n",
              "      <td>231</td>\n",
              "      <td>0.008340</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.00176</td>\n",
              "      <td>...</td>\n",
              "      <td>1.5643</td>\n",
              "      <td>2.3308</td>\n",
              "      <td>9.4959</td>\n",
              "      <td>10.7458</td>\n",
              "      <td>11.0177</td>\n",
              "      <td>4.8066</td>\n",
              "      <td>2.9199</td>\n",
              "      <td>3.1495</td>\n",
              "      <td>4.7666</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.41121</td>\n",
              "      <td>0.79672</td>\n",
              "      <td>0.59257</td>\n",
              "      <td>178</td>\n",
              "      <td>177</td>\n",
              "      <td>0.010858</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.00419</td>\n",
              "      <td>...</td>\n",
              "      <td>3.7805</td>\n",
              "      <td>3.5664</td>\n",
              "      <td>5.2558</td>\n",
              "      <td>14.0403</td>\n",
              "      <td>4.2235</td>\n",
              "      <td>4.6857</td>\n",
              "      <td>4.8460</td>\n",
              "      <td>6.2650</td>\n",
              "      <td>4.0603</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.32790</td>\n",
              "      <td>0.79782</td>\n",
              "      <td>0.53028</td>\n",
              "      <td>236</td>\n",
              "      <td>235</td>\n",
              "      <td>0.008162</td>\n",
              "      <td>0.002669</td>\n",
              "      <td>0.00535</td>\n",
              "      <td>...</td>\n",
              "      <td>6.1727</td>\n",
              "      <td>5.8416</td>\n",
              "      <td>6.0805</td>\n",
              "      <td>5.7621</td>\n",
              "      <td>7.7817</td>\n",
              "      <td>11.6891</td>\n",
              "      <td>8.2103</td>\n",
              "      <td>5.0559</td>\n",
              "      <td>6.1164</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.80903</td>\n",
              "      <td>0.56355</td>\n",
              "      <td>0.28385</td>\n",
              "      <td>417</td>\n",
              "      <td>416</td>\n",
              "      <td>0.004627</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.00064</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0706</td>\n",
              "      <td>3.0190</td>\n",
              "      <td>3.1212</td>\n",
              "      <td>2.4921</td>\n",
              "      <td>3.5844</td>\n",
              "      <td>3.5400</td>\n",
              "      <td>3.3805</td>\n",
              "      <td>3.2003</td>\n",
              "      <td>6.8671</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0.16084</td>\n",
              "      <td>0.56499</td>\n",
              "      <td>0.59194</td>\n",
              "      <td>415</td>\n",
              "      <td>413</td>\n",
              "      <td>0.004550</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.00143</td>\n",
              "      <td>...</td>\n",
              "      <td>1.9704</td>\n",
              "      <td>1.7451</td>\n",
              "      <td>1.8277</td>\n",
              "      <td>2.4976</td>\n",
              "      <td>5.2981</td>\n",
              "      <td>4.2616</td>\n",
              "      <td>6.3042</td>\n",
              "      <td>10.9058</td>\n",
              "      <td>28.4170</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>251</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88389</td>\n",
              "      <td>0.72335</td>\n",
              "      <td>0.46815</td>\n",
              "      <td>381</td>\n",
              "      <td>380</td>\n",
              "      <td>0.005069</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.00076</td>\n",
              "      <td>...</td>\n",
              "      <td>51.5607</td>\n",
              "      <td>44.4641</td>\n",
              "      <td>26.1586</td>\n",
              "      <td>6.3076</td>\n",
              "      <td>2.8601</td>\n",
              "      <td>2.5361</td>\n",
              "      <td>3.5377</td>\n",
              "      <td>3.3545</td>\n",
              "      <td>5.0424</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>251</td>\n",
              "      <td>0</td>\n",
              "      <td>0.83782</td>\n",
              "      <td>0.74890</td>\n",
              "      <td>0.49823</td>\n",
              "      <td>340</td>\n",
              "      <td>339</td>\n",
              "      <td>0.005679</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.00092</td>\n",
              "      <td>...</td>\n",
              "      <td>19.1607</td>\n",
              "      <td>12.8312</td>\n",
              "      <td>8.9434</td>\n",
              "      <td>2.2044</td>\n",
              "      <td>1.9496</td>\n",
              "      <td>1.9664</td>\n",
              "      <td>2.6801</td>\n",
              "      <td>2.8332</td>\n",
              "      <td>3.7131</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>251</td>\n",
              "      <td>0</td>\n",
              "      <td>0.81304</td>\n",
              "      <td>0.76471</td>\n",
              "      <td>0.46374</td>\n",
              "      <td>340</td>\n",
              "      <td>339</td>\n",
              "      <td>0.005676</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.00078</td>\n",
              "      <td>...</td>\n",
              "      <td>62.9927</td>\n",
              "      <td>21.8152</td>\n",
              "      <td>9.2457</td>\n",
              "      <td>4.8555</td>\n",
              "      <td>3.0551</td>\n",
              "      <td>3.0415</td>\n",
              "      <td>4.0116</td>\n",
              "      <td>2.6217</td>\n",
              "      <td>3.1527</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>756 rows × 755 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e052971a-043b-4ba5-b7fd-f5bb38f19b32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e052971a-043b-4ba5-b7fd-f5bb38f19b32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e052971a-043b-4ba5-b7fd-f5bb38f19b32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b0af4fd5-2b6f-4641-a6bf-27dccc9f540f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0af4fd5-2b6f-4641-a6bf-27dccc9f540f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b0af4fd5-2b6f-4641-a6bf-27dccc9f540f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2bbf8db6-520c-48b1-b1db-716d4c30a480\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2bbf8db6-520c-48b1-b1db-716d4c30a480 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Unnamed: 0_level_0_id  Unnamed: 1_level_0_gender  Baseline Features_PPE  \\\n",
              "0                        0                          1                0.85247   \n",
              "1                        0                          1                0.76686   \n",
              "2                        0                          1                0.85083   \n",
              "3                        1                          0                0.41121   \n",
              "4                        1                          0                0.32790   \n",
              "..                     ...                        ...                    ...   \n",
              "751                    250                          0                0.80903   \n",
              "752                    250                          0                0.16084   \n",
              "753                    251                          0                0.88389   \n",
              "754                    251                          0                0.83782   \n",
              "755                    251                          0                0.81304   \n",
              "\n",
              "     Unnamed: 3_level_0_DFA  Unnamed: 4_level_0_RPDE  \\\n",
              "0                   0.71826                  0.57227   \n",
              "1                   0.69481                  0.53966   \n",
              "2                   0.67604                  0.58982   \n",
              "3                   0.79672                  0.59257   \n",
              "4                   0.79782                  0.53028   \n",
              "..                      ...                      ...   \n",
              "751                 0.56355                  0.28385   \n",
              "752                 0.56499                  0.59194   \n",
              "753                 0.72335                  0.46815   \n",
              "754                 0.74890                  0.49823   \n",
              "755                 0.76471                  0.46374   \n",
              "\n",
              "     Unnamed: 5_level_0_numPulses  Unnamed: 6_level_0_numPeriodsPulses  \\\n",
              "0                             240                                  239   \n",
              "1                             234                                  233   \n",
              "2                             232                                  231   \n",
              "3                             178                                  177   \n",
              "4                             236                                  235   \n",
              "..                            ...                                  ...   \n",
              "751                           417                                  416   \n",
              "752                           415                                  413   \n",
              "753                           381                                  380   \n",
              "754                           340                                  339   \n",
              "755                           340                                  339   \n",
              "\n",
              "     Unnamed: 7_level_0_meanPeriodPulses  \\\n",
              "0                               0.008064   \n",
              "1                               0.008258   \n",
              "2                               0.008340   \n",
              "3                               0.010858   \n",
              "4                               0.008162   \n",
              "..                                   ...   \n",
              "751                             0.004627   \n",
              "752                             0.004550   \n",
              "753                             0.005069   \n",
              "754                             0.005679   \n",
              "755                             0.005676   \n",
              "\n",
              "     Unnamed: 8_level_0_stdDevPeriodPulses  Unnamed: 9_level_0_locPctJitter  \\\n",
              "0                                 0.000087                          0.00218   \n",
              "1                                 0.000073                          0.00195   \n",
              "2                                 0.000060                          0.00176   \n",
              "3                                 0.000183                          0.00419   \n",
              "4                                 0.002669                          0.00535   \n",
              "..                                     ...                              ...   \n",
              "751                               0.000052                          0.00064   \n",
              "752                               0.000220                          0.00143   \n",
              "753                               0.000103                          0.00076   \n",
              "754                               0.000055                          0.00092   \n",
              "755                               0.000037                          0.00078   \n",
              "\n",
              "     ...  Unnamed: 745_level_0_tqwt_kurtosisValue_dec_28  \\\n",
              "0    ...                                          1.5620   \n",
              "1    ...                                          1.5589   \n",
              "2    ...                                          1.5643   \n",
              "3    ...                                          3.7805   \n",
              "4    ...                                          6.1727   \n",
              "..   ...                                             ...   \n",
              "751  ...                                          3.0706   \n",
              "752  ...                                          1.9704   \n",
              "753  ...                                         51.5607   \n",
              "754  ...                                         19.1607   \n",
              "755  ...                                         62.9927   \n",
              "\n",
              "     Unnamed: 746_level_0_tqwt_kurtosisValue_dec_29  \\\n",
              "0                                            2.6445   \n",
              "1                                            3.6107   \n",
              "2                                            2.3308   \n",
              "3                                            3.5664   \n",
              "4                                            5.8416   \n",
              "..                                              ...   \n",
              "751                                          3.0190   \n",
              "752                                          1.7451   \n",
              "753                                         44.4641   \n",
              "754                                         12.8312   \n",
              "755                                         21.8152   \n",
              "\n",
              "     Unnamed: 747_level_0_tqwt_kurtosisValue_dec_30  \\\n",
              "0                                            3.8686   \n",
              "1                                           23.5155   \n",
              "2                                            9.4959   \n",
              "3                                            5.2558   \n",
              "4                                            6.0805   \n",
              "..                                              ...   \n",
              "751                                          3.1212   \n",
              "752                                          1.8277   \n",
              "753                                         26.1586   \n",
              "754                                          8.9434   \n",
              "755                                          9.2457   \n",
              "\n",
              "     Unnamed: 748_level_0_tqwt_kurtosisValue_dec_31  \\\n",
              "0                                            4.2105   \n",
              "1                                           14.1962   \n",
              "2                                           10.7458   \n",
              "3                                           14.0403   \n",
              "4                                            5.7621   \n",
              "..                                              ...   \n",
              "751                                          2.4921   \n",
              "752                                          2.4976   \n",
              "753                                          6.3076   \n",
              "754                                          2.2044   \n",
              "755                                          4.8555   \n",
              "\n",
              "     Unnamed: 749_level_0_tqwt_kurtosisValue_dec_32  \\\n",
              "0                                            5.1221   \n",
              "1                                           11.0261   \n",
              "2                                           11.0177   \n",
              "3                                            4.2235   \n",
              "4                                            7.7817   \n",
              "..                                              ...   \n",
              "751                                          3.5844   \n",
              "752                                          5.2981   \n",
              "753                                          2.8601   \n",
              "754                                          1.9496   \n",
              "755                                          3.0551   \n",
              "\n",
              "     Unnamed: 750_level_0_tqwt_kurtosisValue_dec_33  \\\n",
              "0                                            4.4625   \n",
              "1                                            9.5082   \n",
              "2                                            4.8066   \n",
              "3                                            4.6857   \n",
              "4                                           11.6891   \n",
              "..                                              ...   \n",
              "751                                          3.5400   \n",
              "752                                          4.2616   \n",
              "753                                          2.5361   \n",
              "754                                          1.9664   \n",
              "755                                          3.0415   \n",
              "\n",
              "     Unnamed: 751_level_0_tqwt_kurtosisValue_dec_34  \\\n",
              "0                                            2.6202   \n",
              "1                                            6.5245   \n",
              "2                                            2.9199   \n",
              "3                                            4.8460   \n",
              "4                                            8.2103   \n",
              "..                                              ...   \n",
              "751                                          3.3805   \n",
              "752                                          6.3042   \n",
              "753                                          3.5377   \n",
              "754                                          2.6801   \n",
              "755                                          4.0116   \n",
              "\n",
              "     Unnamed: 752_level_0_tqwt_kurtosisValue_dec_35  \\\n",
              "0                                            3.0004   \n",
              "1                                            6.3431   \n",
              "2                                            3.1495   \n",
              "3                                            6.2650   \n",
              "4                                            5.0559   \n",
              "..                                              ...   \n",
              "751                                          3.2003   \n",
              "752                                         10.9058   \n",
              "753                                          3.3545   \n",
              "754                                          2.8332   \n",
              "755                                          2.6217   \n",
              "\n",
              "     Unnamed: 753_level_0_tqwt_kurtosisValue_dec_36  \\\n",
              "0                                           18.9405   \n",
              "1                                           45.1780   \n",
              "2                                            4.7666   \n",
              "3                                            4.0603   \n",
              "4                                            6.1164   \n",
              "..                                              ...   \n",
              "751                                          6.8671   \n",
              "752                                         28.4170   \n",
              "753                                          5.0424   \n",
              "754                                          3.7131   \n",
              "755                                          3.1527   \n",
              "\n",
              "     Unnamed: 754_level_0_class  \n",
              "0                             1  \n",
              "1                             1  \n",
              "2                             1  \n",
              "3                             1  \n",
              "4                             1  \n",
              "..                          ...  \n",
              "751                           0  \n",
              "752                           0  \n",
              "753                           0  \n",
              "754                           0  \n",
              "755                           0  \n",
              "\n",
              "[756 rows x 755 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtQXO6__r_4d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "X6pnr7avffM4",
        "outputId": "e37ca104-ae36-4170-d4e4-0fd2fc0eb340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2220596738.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ===========================\n",
        "# Step 6: Random Forest + Hyperparameter Tuning\n",
        "# ===========================\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [None, 10, 20],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_resampled, y_resampled)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yE1fUvYlKhW",
        "outputId": "d32cfc4b-a4ed-443a-c958-4b12ce0e57d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [18:04:16] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Best cross-validation accuracy: 0.9397089478859388\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ===========================\n",
        "# Step 6: XGBoost + Hyperparameter Tuning\n",
        "# ===========================\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"subsample\": [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_resampled, y_resampled)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REgNXolelQNG",
        "outputId": "4cba0398-f8db-4d64-c062-9b355c366857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best cross-validation accuracy: 0.9485742379547689\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"C\": [0.1, 1, 10],\n",
        "    \"gamma\": [\"scale\", \"auto\"],\n",
        "    \"kernel\": [\"linear\", \"rbf\"]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=svm,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_resampled, y_resampled)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKetNp2-2xI0"
      },
      "outputs": [],
      "source": [
        "best_svm = grid.best_estimator_\n",
        "\n",
        "y_pred = best_svm.predict(X_test)\n",
        "\n",
        "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gimG_t56le0e"
      },
      "source": [
        "# trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5TqCKH0e0Mu",
        "outputId": "c79c2361-e9d9-46ce-d9a4-ed3edf24c672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original shape: (756, 754)\n",
            "reduced shape: (756, 50)\n"
          ]
        }
      ],
      "source": [
        "X = df.drop(columns=[\"Unnamed: 754_level_0_class\"])   # replace 'class' with correct label column name\n",
        "y = df[\"Unnamed: 754_level_0_class\"]\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(\"original shape:\", X.shape)\n",
        "print(\"reduced shape:\", X_pca.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyTbseJfcwdP",
        "outputId": "c2e72ea1-8e12-4cea-e91d-2b9d3f085699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before SMOTE: {1: 451, 0: 153}\n",
            "After SMOTE: {1: 451, 0: 451}\n",
            "Accuracy: 0.8618421052631579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.74      0.73        39\n",
            "           1       0.91      0.90      0.91       113\n",
            "\n",
            "    accuracy                           0.86       152\n",
            "   macro avg       0.82      0.82      0.82       152\n",
            "weighted avg       0.86      0.86      0.86       152\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# --- Train/Test Split (before SMOTE) ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- Apply SMOTE only on training data ---\n",
        "smote = SMOTE(k_neighbors=5, random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Before SMOTE:\", y_train.value_counts().to_dict())\n",
        "print(\"After SMOTE:\", pd.Series(y_train_res).value_counts().to_dict())\n",
        "\n",
        "# Train Gradient Boosting\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=200,   # number of boosting stages\n",
        "    learning_rate=0.05, # lower lr + more estimators = better accuracy\n",
        "    max_depth=3,        # tree depth\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gb.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = gb.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK7oBjTNfpHd",
        "outputId": "0b21c148-6cf2-4ce3-ebba-f8726b40f57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.8421052631578947\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.42      0.57        38\n",
            "           1       0.84      0.98      0.90       114\n",
            "\n",
            "    accuracy                           0.84       152\n",
            "   macro avg       0.86      0.70      0.74       152\n",
            "weighted avg       0.85      0.84      0.82       152\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#random forest\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbni8jDQfsTY",
        "outputId": "4047fd60-1c44-48d5-f33e-acce180a87b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.58      0.67        38\n",
            "           1       0.87      0.95      0.91       114\n",
            "\n",
            "    accuracy                           0.86       152\n",
            "   macro avg       0.83      0.76      0.79       152\n",
            "weighted avg       0.85      0.86      0.85       152\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#another classical model\n",
        " #(logistic regression)\n",
        "log_reg = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "log_reg.fit(X_train, y_train)\n",
        "print(\"Logistic Regression:\")\n",
        "\n",
        "print(classification_report(y_test, log_reg.predict(X_test)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CiVvn7XgYtm",
        "outputId": "a979483c-e396-421c-a071-507644a57430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.39      0.56        38\n",
            "           1       0.83      0.99      0.90       114\n",
            "\n",
            "    accuracy                           0.84       152\n",
            "   macro avg       0.88      0.69      0.73       152\n",
            "weighted avg       0.86      0.84      0.82       152\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#svm\n",
        "svm = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", SVC(kernel=\"rbf\", probability=True))\n",
        "])\n",
        "svm.fit(X_train, y_train)\n",
        "print(\"SVM\")\n",
        "print(classification_report(y_test, svm.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oYT8XtrgyIM",
        "outputId": "558f1925-ec11-4089-ca5d-c2f0825dff4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logistic regression: 0.8158\n",
            "SVM (with rbf kernel): 0.8158\n",
            "random forest: 0.8421\n",
            "gradient boosting: 0.8553\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=50, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "models = {\n",
        "    \"logistic regression\": LogisticRegression(max_iter=1000),\n",
        "    \"SVM (with rbf kernel)\": SVC(kernel='rbf', probability=True),\n",
        "    \"random forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
        "    \"gradient boosting\": GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name}: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxEjei6vyW5K"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"Unnamed: 754_level_0_class\"])   # features\n",
        "y = df[\"Unnamed: 754_level_0_class\"]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ===========================\n",
        "# Step 3: PCA (dimensionality reduction)\n",
        "# ===========================\n",
        "pca = PCA(n_components=50, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(\"Original shape:\", X.shape)\n",
        "print(\"Reduced shape (PCA):\", X_pca.shape)\n",
        "\n",
        "# ===========================\n",
        "# Step 4: Feature Selection with RFE\n",
        "# (use Logistic Regression as estimator for RFE)\n",
        "# ===========================\n",
        "log_reg = LogisticRegression(max_iter=500, solver=\"liblinear\")\n",
        "rfe = RFE(log_reg, n_features_to_select=50)\n",
        "X_selected = rfe.fit_transform(X_pca, y)\n",
        "\n",
        "print(\"Shape after RFE:\", X_selected.shape)\n",
        "\n",
        "# ===========================\n",
        "# Step 5: Handle imbalance with SMOTE\n",
        "# ===========================\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_selected, y)\n",
        "\n",
        "print(\"Before SMOTE:\", np.bincount(y))\n",
        "print(\"After SMOTE:\", np.bincount(y_resampled))\n",
        "\n",
        "# ===========================\n",
        "# Step 6: Gradient Boosting + Hyperparameter Tuning\n",
        "# ===========================\n",
        "gbc = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=gbc,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_resampled, y_resampled)\n",
        "\n",
        "# ===========================\n",
        "# Step 7: Results\n",
        "# ===========================\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid.best_score_)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
